{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and setting up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "from svgpathtools import parse_path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "features_dir= os.path.join(results_dir,'features')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)  \n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)  \n",
    "\n",
    "if not os.path.exists(features_dir):\n",
    "    os.makedirs(features_dir)\n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))        \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up connection to mongo and creating main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "key  = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['semantic_parts']\n",
    "coll = db['sketchpad_basic']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'pilot0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sketches = coll.find({'iterationName':iterationName}).count()\n",
    "print 'We have {} annotations so far.'.format(num_sketches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jefan = ['A1MMCS8S8CTWKU','A1MMCS8S8CTWKV','A1MMCS8S8CTWKS']\n",
    "hawkrobe = ['A1BOIDKD33QSDK']\n",
    "kmukherjee = ['A1WU4IHJNQGVAY']\n",
    "researchers = jefan + hawkrobe  + kmukherjee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_assignments = coll.find({'iterationName':iterationName}).distinct('aID')\n",
    "print 'We have had {} unique sessions'.format( len(unique_assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get list of unique_assignments\n",
    "unique_assignments = coll.find({'iterationName':iterationName}).distinct('aID')\n",
    "\n",
    "### initialize a bunch of stuff\n",
    "orig_gameID = [] # the gameID from which this sketch was sourced\n",
    "outcome =[] #original outcome for that trial- true/false\n",
    "orig_trial_num = [] # the trialnum in the original game from which this sketch was sourced -- \n",
    "sketch_id = [] # concatenation of orig_gameID and orig_trial_num -- \n",
    "assignmentID = [] # the session in which this annotation was collected -- \n",
    "annotation_id = [] # the unique ID for each annotation trial (different for each session the same sketch appears in)\n",
    "category = [] # e.g., \"chair\"\n",
    "target = [] # e.g., \"inlay\"\n",
    "condition = [] # e.g., \"closer\" vs. \"further\" or \"repeated\" vs. \"control\n",
    "trial_num = [] \n",
    "workerID = [] #mTurk workerId\n",
    "spline_id =[] #unique spline identifier\n",
    "time_submitted = [] # when the participant clicked \"next sketch\"\n",
    "time_labeled = [] # unique to each spline labeled\n",
    "time_clicked = [] # when this spline was clicked/selected\n",
    "num_strokes_in_sketch = [] # how many strokes in this sketch\n",
    "num_splines_in_sketch = [] # how many spline elements in this sketch\n",
    "stroke_num = [] # which stroke number this labeled spline came from\n",
    "cumulative_spline_num = [] # spline index in the cumulative spline sequence for the entire sketch\n",
    "within_stroke_spline_num = [] # spline index for the current stroke\n",
    "cumulative_bout_num= [] #which bout of annotation the spline belonged to\n",
    "part_bout_num =[] #which part-specific bout of annotation the spline belonged to\n",
    "label = [] # the label provided by the participant\n",
    "spline_svg_string = [] # the svg spline string that earned this label\n",
    "sketch_svg_string = [] # the entire svg string correponding to this sketch\n",
    "annotation_flag = [] # this is True if all splines were labeled as the same thing\n",
    "annotation_spline_id = [] #unique identifier for specific annotation of a spline\n",
    "png=[] #png string for the annotated sketch\n",
    "stroke_id=[]\n",
    "timestamp=[]\n",
    "\n",
    "## loop through all the unique assignments that have submitted things\n",
    "for this_assignment, aID in enumerate(unique_assignments):\n",
    "    if this_assignment%10==0:\n",
    "        print 'Analyzing sketches from assignment {} of {}  ...'.format(this_assignment, len(unique_assignments))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    ### get all the sketch recs for this assignment\n",
    "    sketch_recs = coll.find({'$and': [{'iterationName':iterationName}, {'aID':aID}]}).sort('time')\n",
    "\n",
    "    try:\n",
    "\n",
    "        for sketch_ind,sketch in enumerate(sketch_recs):\n",
    "            ## get annotations embedded within record\n",
    "            sketch_cat = sketch['category']\n",
    "            annotations_string = sketch['annotations']\n",
    "            \n",
    "    \n",
    "            ## convert to json dictionary\n",
    "            _annotations_dict = json.loads(annotations_string)  \n",
    "           \n",
    "            annotations_dict = _annotations_dict[0][sketch_cat]\n",
    "            _timestamp = coll.find({'$and': [{'iterationName':iterationName}, {'aID':aID}]}).distinct('time')[sketch_ind]\n",
    "            png_string = _annotations_dict[0]['png']\n",
    "            num_splines = len(annotations_dict)\n",
    "            for annotation in annotations_dict:\n",
    "                assert sketch['numSplines']==num_splines                \n",
    "                ## get spline-level metadata\n",
    "            \n",
    "                workerID.append(h.encode(key,sketch['wID']))\n",
    "                label.append(annotation['label'])\n",
    "                stroke_num.append(annotation['strokeNum'])\n",
    "                spline_svg_string.append(annotation['svgString'])\n",
    "                cumulative_spline_num.append(annotation['cumulativeSplineNum'])\n",
    "                within_stroke_spline_num.append(annotation['withinStrokeSplineNum'])\n",
    "                time_clicked.append(annotation['timeClicked'])\n",
    "                time_labeled.append(annotation['timeLabeled'])\n",
    "                spline_id.append('{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],annotation['cumulativeSplineNum']))\n",
    "                stroke_id.append('{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],annotation['strokeNum']))\n",
    "                cumulative_bout_num.append(annotation['boutNum'])\n",
    "                part_bout_num.append(annotation['partBoutNum'])\n",
    "                ## get sketch-level metadata\n",
    "                orig_gameID.append(sketch['originalGameID'])   \n",
    "                outcome.append(sketch['originalOutcome'])\n",
    "                orig_trial_num.append(sketch['originalTrialNum'])\n",
    "                sketch_id.append('{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum']))\n",
    "                annotation_id.append('{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],sketch['aID']))\n",
    "                assignmentID.append(sketch['aID'])\n",
    "                category.append(sketch['category'])\n",
    "                target.append(sketch['target'])\n",
    "                png.append(png_string)\n",
    "                timestamp.append(_timestamp)\n",
    "                condition.append(sketch['condition'])\n",
    "                time_submitted.append(sketch['time'])\n",
    "                trial_num.append(sketch['trialNum'])\n",
    "                num_splines_in_sketch.append(sketch['numSplines'])\n",
    "                num_strokes_in_sketch.append(sketch['numStrokes'])\n",
    "                sketch_svg_string.append(sketch['svg'])\n",
    "                annotation_flag.append(sketch['sameAnnotflag'])\n",
    "                annotation_spline_id.append('{}_{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],sketch['aID'],annotation['cumulativeSplineNum']))\n",
    "                \n",
    "    except AssertionError:\n",
    "        print 'There were unequal numbers for sketch[\"numSplines\"] vs. num_splines for sketch {} from {}'.\\\n",
    "                format(sketch['trialNum'], sketch['aID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make group dataframe \n",
    "D = pd.DataFrame([workerID,orig_gameID,timestamp, orig_trial_num, outcome, sketch_id, category, assignmentID,  target, \\\n",
    "                  annotation_id, condition, trial_num, time_submitted,\\\n",
    "                 time_labeled, time_clicked, num_strokes_in_sketch, num_splines_in_sketch,\\\n",
    "                 stroke_num, cumulative_spline_num, within_stroke_spline_num, cumulative_bout_num,\\\n",
    "                 part_bout_num, label, spline_svg_string, sketch_svg_string, spline_id, stroke_id,\\\n",
    "                  annotation_spline_id,png])\n",
    "D = D.transpose()\n",
    "D.columns = ['workerID','orig_gameID', 'timestamp','orig_trial_num','outcome', 'sketch_id', 'category', 'assignmentID', 'target',\\\n",
    "             'annotation_id', 'condition', 'trial_num', 'time_submitted',\\\n",
    "             'time_labeled', 'time_clicked', 'num_strokes_in_sketch', 'num_splines_in_sketch',\\\n",
    "             'stroke_num', 'cumulative_spline_num', 'within_stroke_spline_num', 'cumulative_bout_num', 'part_bout_num', 'label',\\\n",
    "             'spline_svg_string', 'sketch_svg_string', 'spline_id','stroke_id','annotation_spline_id','png']\n",
    "D=D[D['assignmentID']!='']\n",
    "\n",
    "\n",
    "print 'Annotations dataframe contains {} rows and {} columns.'.format(D.shape[0],D.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check to see what dataframe looks like\n",
    "D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Changing the NAs to \"None\" strings\n",
    "\n",
    "for ind, row in D.iterrows():\n",
    "    if row['label'] is None:\n",
    "        row['label'] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a dictionary of dictionaries that maps user input labels to our main labels of interest\n",
    "#Skip this cell to retain the original annotations\n",
    "\n",
    "\n",
    "maplist_dict={}\n",
    "maplist_dict['car'] ={'body':['body','59 decal','Body and hood','Body and windshield','Gas Cap', 'gas tank','Logo','Number','Number Decal','logo','grill',\\\n",
    "                'Grille','Grill','hubcap','seat','grille','ROOF','Roof','roof','number','59 decal','side mirror','Roof Panel',\\\n",
    "                 'Undercarriage','numbers','rearview mirror','NUMBER','Top','top','Racing Decal','Side Mirror','convertible top'],\n",
    " 'bumper':['bumper','Fender','fender','fender well','front bumber','Bumper','Bumper and Hood','step'],\n",
    " 'door':['door','DOOR HANDLE','door handle','handle'],\n",
    " 'headlight':['headlight','taillight'],\n",
    " 'hood':['hood','hood release','Hood Ornament','mirror','Mirror','hood ornament'],\n",
    " 'trunk':['trunk','Exhaust'],\n",
    " 'unknown':['Letter R','Letter e','Letter D','letter D','Says the word Drive','unknown','text','Wind','eye','Arrow','Light Beams',\\\n",
    "           'Light beams','driver','Tree','hand','horn','Word',\"it's just words, no picture to label\",'words','Pavement','Payement'\\\n",
    "           'Color','Door Handle', 'Subject just wrote \"red\"','subject just wrote \"red\"','Gas tank',\"The Word Red\",\"The Sun\"\\\n",
    "           'sun','clouds','tail lights','vent','The word blue', 'The Word Red','spoiler','None','Sun','Color','sun',\n",
    "           'The Sun', 'Payement','subject just wrote \"red\"'],\n",
    " 'wheel':['rim','Tire','tire','tires','wheel','wheel well','Axle','spokes','Spells the word Red','lug nuts','lug nut','rims'],\n",
    " 'window':['window'],\n",
    " 'windshield':['windshield','Steering wheel','wiper']\n",
    "}\n",
    "maplist_dict['bird']={'beak':['beak','jaw'],\n",
    "                      'body':['body','chest','back','speckles','Markings','marking','markings','Marking','Coloring','coloring'],\n",
    "                      'eye':['eye'],\n",
    "                      'feet':['feet','Toes'],\n",
    "                      'head':['head','neck','Neck','facial marking'],\n",
    "                      'leg':['leg'],\n",
    "                      'tail':['tail'],\n",
    "                      'wing':['wing','feather','feathers','Feathers','Feather'],\n",
    "                      'unknown':['unknown','B','I','R','D','This isnt a bird','not sketch','c','h',\\\n",
    "                                'i','r','p','Not a bird: The word \"orange\"','sky','Word','The word Yellow',\\\n",
    "                                'Pointing to chest','sun',\"Letters spelling 'chirp'\",'letter y','letter e','letter l'\\\n",
    "                                ,'letter w', 'letter o','Shading','Sound of Bird','Words','this just spells bird','Cloud',\\\n",
    "                                'Sun','sunbeams','None','letter','the sound it makes','The sound it makes']}\n",
    "\n",
    "maplist_dict['dog']={'body':['body','chest','Stomach','back','butt','Butt','fur','fur ','both head and body','Back',\\\n",
    "                            'Belly','rear','skin fold','ribs'],\n",
    "                     'ear':['ear'],\n",
    "                     'eye':['eye','Eye Brow'],\n",
    "                     'head':['head','Nose','Nose ','nose','Nose','Nostrils','snout','NOSE','Snout','snout area','face','mask'],\n",
    "                     'leg':['leg'],\n",
    "                     'mouth':['mout','tongue','muzzle','jaw','Tongue','Muzzle','chin'],\n",
    "                     'neck':['neck'],\n",
    "                     'paw':['paw','foot'],\n",
    "                     'tail':['tail'],\n",
    "                     'unknown':['unknown','Straight line in the letter \"D\"','Curved part of the letter \"D\"','left half of the letter \"O\"',\\\n",
    "                               'Right part of the letter \"O\"','Letter \"G\"','cheating','Person just wrote words','Non-Animal',\\\n",
    "                               'not a vaild pict of a dog','letter','W','o','f','word','letter b','Shadow','SHadow','Text',\\\n",
    "                               'spelling of dog','smiley face','O','F','R','K','Words \"Woof Bark\"','not a drawing of a dog','Word','color',\\\n",
    "                               'shading','writing','text','None','Hair','stomach','Stripes','Fur','word description',\\\n",
    "                               'leg and paw','Leg and Paw','words written to describe drawing','name of dog type']}\n",
    "\n",
    "maplist_dict['chair']={'armrest':['armrest','sides','support slats','support slat','armrest support','decorative wood pane',\\\n",
    "                                 'side spindles','Chair frame','Side support','Design Elements','Leg and armrest','arm rest',\\\n",
    "                                 'bars','bar','arm rest support','arm support','Arm support'],\n",
    "                       'backrest':['backrest','headrest','Spindle','spindles','spindels','back support'],\n",
    "                       'seat':['seat', 'Chair support','cushion'],\n",
    "                       'leg':['leg','bottom frame','spindle','Support Bar','wheel','leg rail','leg support','support beam',\\\n",
    "                             'Wheel','bottom brace','stretcher','supporting wood','Leg support','top of leg','foot',\\\n",
    "                             'Reinforcement for legs','Brace','supports','support for legs','Bottom Support','Leg support',\\\n",
    "                             'Stretcher','wood beam connecting legs','Wood beam connecting legs','brace','braces','Struts','Leg Support',\\\n",
    "                              'metal support','support','Leg Brace'],\n",
    "                       'unknown':['unknown','frame','Descriptive label','letters','Not a chair','Frame','Decoration','Structure',\\\n",
    "                                 'name ','Label','Words - Bulky Garage','Part of O','letter r','Part of letter a',\\\n",
    "                                 'Part of letter n','Part of letter g','Part of letter e','Part of arrow',\\\n",
    "                                 'The word \"sit\"','word','text','not a sketch','base','rail','color of chair','chair was written',\\\n",
    "                                 'not a sketch, chair was written', 'None','footrest','Color of Chair','Structural Support','Cross beams','Support','Crossbars','Strut']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of unique labels before mapping\n",
    "D.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.annotation_spline_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get total number of splines for labels of interest before mapping\n",
    "\n",
    "total_splines_um = D[(D['category']=='chair')&(D['label'].isin(['armrest','backrest','seat','leg','unknown']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n",
    "+\\\n",
    "D[(D['category']=='bird')&(D['label'].isin(['beak','body','eye','feet','head','leg','tail','wing','unknown']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n",
    "+\\\n",
    "D[(D['category']=='dog')&(D['label'].isin(['body','ear','eye','head','leg','mouth','neck','paw','tail','unknown']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n",
    "+\\\n",
    "D[(D['category']=='car')&(D['label'].isin(['body','bumper','door','headlight','hood','trunk','unknown','wheel','window','windshield']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Actually doing the mapping\n",
    "unique_cats = np.unique(D['category'])\n",
    "\n",
    "for this_cat in unique_cats:\n",
    "    maplist=maplist_dict[this_cat]\n",
    "    reversed_dict = {val: key for key in maplist for val in maplist[key]}\n",
    "    D.loc[D['category']==this_cat,'label']=D[D['category']==this_cat]['label'].map(reversed_dict).fillna(D['label'])\n",
    "  #  D.loc[D['category']==this_cat,'label']=D[D['category']==this_cat]['label'].map(reversed_dict)\n",
    "     \n",
    "                                                                                                        \n",
    "                                                                                                        \n",
    "                                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get total number of splines for labels of interest after mapping\n",
    "\n",
    "total_splines_m = D[(D['category']=='chair')&(D['label'].isin(['armrest','backrest','seat','leg','unknown']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n",
    "+\\\n",
    "D[(D['category']=='bird')&(D['label'].isin(['beak','body','eye','feet','head','leg','tail','wing','unknown']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n",
    "+\\\n",
    "D[(D['category']=='dog')&(D['label'].isin(['body','ear','eye','head','leg','mouth','neck','paw','tail','unknown']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n",
    "+\\\n",
    "D[(D['category']=='car')&(D['label'].isin(['body','bumper','door','headlight','hood','trunk','unknown','wheel','window','windshield']))]\\\n",
    ".groupby('label').agg('count')['annotation_spline_id'].sum()\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_splines_m-total_splines_um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_splines_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a count of how many unique sketches have been annotated and how many unique annotations do we have in total?\n",
    "\n",
    "unique_sketches = np.unique(D['sketch_id'].values)\n",
    "print 'We have {} annotations of {} unique sketches.'.format(len(D['annotation_id'].unique()),len(unique_sketches))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Removing any annotations that don't have all splines annotated\n",
    "\n",
    "for this_sketch in unique_sketches:\n",
    "    DS=D[D['sketch_id']==this_sketch]\n",
    "    for this_annot in np.unique(DS['annotation_id']):\n",
    "        DSS= DS[DS['annotation_id']==this_annot]\n",
    "        if DSS[DSS['label']== 'None'].shape[0]>0:\n",
    "            D=D[D['annotation_id']!=this_annot]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##How many annotations after filtering?\n",
    "len(D['annotation_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing any sketches that weren't annotated by at least 3 different workers\n",
    "num_annots=3\n",
    "for this_sketch in unique_sketches:\n",
    "    DS = D[D['sketch_id']==this_sketch]\n",
    "    if DS.workerID.nunique()<num_annots:\n",
    "        D=D[D['sketch_id']!=this_sketch]\n",
    "unique_sketches=np.unique(D.sketch_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##How many annotations and sketches after filtering?\n",
    "print 'We now have {} annotations of {} sketches'.format(len(D['annotation_id'].unique()),len(D['sketch_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get number of times each sketch has been annotated\n",
    "num_times_annotated = []\n",
    "for this_sketch_id in unique_sketches:\n",
    "    num_times_annotated.append(D[D['sketch_id']==this_sketch_id]['assignmentID'].nunique())\n",
    "    \n",
    "## make a histogram\n",
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(6,5))\n",
    "h = plt.hist(num_times_annotated)\n",
    "plt.xticks(np.arange(0, 4, step=1))\n",
    "plt.title('Times each sketch has been annotated')\n",
    "plt.ylabel('number of sketches')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Subsetting for sketches that have been annotated 3 times\n",
    "num_annots=3\n",
    "##Why are some assignment IDs blank?\n",
    "D=D[D['assignmentID']!='']\n",
    "for this_sketch_id in unique_sketches:\n",
    "    DS= D[D['sketch_id']==this_sketch_id]\n",
    "    if DS['assignmentID'].nunique()>num_annots:\n",
    "        for i in range(DS['assignmentID'].nunique()-num_annots):\n",
    "            D=D.loc[D.timestamp!=DS.timestamp.min()]\n",
    "            DS=DS.loc[DS.timestamp!=DS.timestamp.min()]\n",
    "unique_sketches = np.unique(D['sketch_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##How many sketches do we have with 3 annotations?\n",
    "len(np.unique(D.sketch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate out the PNG dataframe, to reduce redundancy/bloat in master dataframe\n",
    "D_png = D.groupby('sketch_id')['png'].unique().reset_index()\n",
    "D_png.to_csv(os.path.join(csv_dir, 'semantic_parts_annotated_pngstring.csv'),index=False)\n",
    "\n",
    "## save out master semantic parts annotation dataframe\n",
    "D2 = D.drop('png',axis=1) # remove reundandant png column (split off into different dataframe, to reduce bloat)\n",
    "D2.to_csv(os.path.join(csv_dir, 'semantic_parts_annotated_data.csv'),index=False)\n",
    "D2.to_pickle(os.path.join(csv_dir, 'semantic_parts_annotated_data_pckl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating spline and stroke level dataframes for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###D = pd.read_csv(os.path.join(csv_dir, 'semantic_parts_annotated_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the list of unique labels applied to sketches\n",
    "unique_labels = np.unique(D.label.values)\n",
    "\n",
    "## Removing Nones and obviously wrong super long lables\n",
    "unique_labels = [i for i in unique_labels if i is not None]\n",
    "unique_labels = [i for i in unique_labels if len(i)<900]\n",
    "\n",
    "print 'we have {} unique labels'.format(len( unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create empty dictionary with categories as keys. We will use this to store part occurrence data for our categories\n",
    "label_vect_dict = {unique_cats[0]:None,unique_cats[1]:None,unique_cats[2]:None,unique_cats[3]:None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create vectors that contain the number of part instances in each sketch\n",
    "\n",
    "for category in unique_cats:\n",
    "    DS= D[D['category']==category]\n",
    "    unique_sketches_in_cat = np.unique(DS['sketch_id'])\n",
    "    unique_labels_in_cat = np.unique(DS['label'])\n",
    "    ## initialize matrix that has the correct dimensions\n",
    "    Label_Vec = np.zeros((len(unique_sketches_in_cat),len(unique_labels_in_cat)), dtype=int)\n",
    "    unique_labels_in_cat= np.array(unique_labels_in_cat)\n",
    "    for s,this_sketch in enumerate(unique_sketches_in_cat):\n",
    "        label_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        DSS = DS[DS['sketch_id']==this_sketch]\n",
    "        annotation_ids = np.unique(DSS['annotation_id'].values)    \n",
    "        for this_annotation in annotation_ids:\n",
    "            DSA = DSS[DSS['annotation_id']==this_annotation]\n",
    "            label_list = DSA.label.values\n",
    "            for this_label in label_list:\n",
    "                label_ind = unique_labels_in_cat==this_label\n",
    "                label_vec[label_ind] += 1\n",
    "            \n",
    "        Label_Vec[s,:]=label_vec/num_annots\n",
    "    label_vect_dict[category]= Label_Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels=[]\n",
    "valid_labels_dict={}\n",
    "for category in unique_cats:\n",
    "    vect = label_vect_dict[category]\n",
    "    thresh = 0\n",
    "    #print 'These are the labels that appear at least {} times:'.format(thresh)\n",
    "    #print unique_labels[np.sum(Label_Vec,0)>thresh]\n",
    "    unique_labels_in_cat = np.unique(D[D['category']==category]['label'])\n",
    "    plot_labels= unique_labels_in_cat[np.sum(vect,0)>thresh]\n",
    "    valid_labels_dict[category]=plot_labels\n",
    "    valid_labels.append(plot_labels)\n",
    "\n",
    "\n",
    "    prop_labels=[]\n",
    "    for part in plot_labels:\n",
    "        DS=D[D['category']==category]\n",
    "        prop_labels.append(DS[DS['label']==part]['annotation_id'].nunique()/DS['annotation_id'].nunique())\n",
    "    \n",
    "    \n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.ylim(0,1)\n",
    "    h = plt.bar(plot_labels,prop_labels)\n",
    "    plt.title('Proportion of {} annotations with labels'.format(category))\n",
    "    plt.ylabel('proportion of annotations')\n",
    "    plt.xlabel('Part')\n",
    "    \n",
    "##flattening valid labels\n",
    "valid_labels = [item for sublist in valid_labels for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a spline-level df where the modal label is set as the 'true' label for any given spline\n",
    "spline_df= D.groupby('spline_id').agg(lambda x: Counter(x).most_common(1)[0][0])\n",
    "spline_df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a stroke-level dataframe that takes the mode value of annotation for its children splines to set as its\n",
    "##label value\n",
    "\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "stroke_svgs=OrderedDict()\n",
    "\n",
    "for category in unique_cats:\n",
    "    DS=D[D['category']==category]\n",
    "    for sketch in np.unique(DS['sketch_id']):\n",
    "        DSS=DS[DS['sketch_id']==sketch]\n",
    "        for stroke in np.unique(DSS['stroke_num']):\n",
    "            DSA=DSS[DSS['stroke_num']==stroke]\n",
    "            DSA=DSA.reset_index()\n",
    "            stroke_svgs[DSA['stroke_id'][0]] = DSA['sketch_svg_string'][0][stroke]\n",
    "                    \n",
    "stroke_svg_df= pd.DataFrame.from_dict(stroke_svgs, orient='index')    \n",
    "stroke_group_data= D.groupby('stroke_id').agg(lambda x: Counter(x).most_common(1)[0][0])\n",
    "labels= pd.DataFrame(stroke_group_data[['sketch_id','label','stroke_num','condition','target','category','outcome']])\n",
    "stroke_df=pd.merge(stroke_svg_df,labels,left_index=True, right_index =True)\n",
    "stroke_df.reset_index(level=0, inplace=True)\n",
    "stroke_df=stroke_df.rename(index=str, columns={\"index\": \"stroke_id\", 0: \"svg\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding total arclength information to stroke dataframe\n",
    "from svgpathtools import parse_path\n",
    "import svgpathtools\n",
    "\n",
    "def calculate_arclength(svg):\n",
    "    try:\n",
    "        arclength= parse_path(svg).length()\n",
    "    except ZeroDivisionError:\n",
    "        print 'zero div error'\n",
    "        arclength = 0\n",
    "    return arclength\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_df['arc_length'] = stroke_df['svg'].apply(calculate_arclength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating feature vectors and normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This is where we make a num unique labels * 2 X number of sketches vector \n",
    "\n",
    "feature_vec = np.zeros((len(stroke_df.sketch_id.unique()),len(valid_labels)*2), dtype=int)\n",
    "ind=0\n",
    "start_pos=0\n",
    "end_pos=0\n",
    "meta_list=[]\n",
    "cols = ['sketch_id','target','condition','category','outcome']\n",
    "\n",
    "for cat in unique_cats:\n",
    "  \n",
    "    DS= stroke_df[stroke_df['category']==cat]\n",
    "    unique_labels_in_cat=valid_labels_dict[cat]\n",
    "    unique_sketches_in_cat=DS['sketch_id'].unique()\n",
    "    start_pos = end_pos\n",
    "    end_pos+= len(unique_labels_in_cat)\n",
    "    print start_pos, end_pos\n",
    "    clear_output(wait=True)\n",
    "    Label_Vec = np.zeros((len(unique_sketches_in_cat),len(unique_labels_in_cat)*2), dtype=int)\n",
    "    arc_length_vec = np.zeros((len(unique_sketches_in_cat),len(valid_labels_dict[cat])), dtype=int)\n",
    "    for s,sketch in enumerate(unique_sketches_in_cat):\n",
    "        \n",
    "        label_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        arc_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        DSA=DS[DS['sketch_id']==sketch]\n",
    "      \n",
    "        meta_list.append(pd.Series([DSA['sketch_id'].unique(),DSA['target'].unique(),DSA['condition'].unique(),DSA['category'].unique(),DSA['outcome'].unique()], index=cols))\n",
    "        label_list = DSA.label.values        \n",
    "        for label in label_list:\n",
    "            if label in unique_labels_in_cat:\n",
    "                label_ind = unique_labels_in_cat==label\n",
    "                label_vec[label_ind] += 1\n",
    "        for label in unique_labels_in_cat:\n",
    "            DSB=DSA[DSA['label']==label]\n",
    "            label_ind = unique_labels_in_cat==label\n",
    "            arc_vec[label_ind] = DSB['arc_length'].sum()\n",
    "            \n",
    "        \n",
    "        feature_vec[ind,start_pos:end_pos]=label_vec\n",
    "        feature_vec[ind,start_pos+len(valid_labels):end_pos+len(valid_labels)]=arc_vec\n",
    "        ind+=1\n",
    "feature_vec_meta = pd.DataFrame(meta_list, columns=cols)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Changing column values from np arrays to strings/boolean\n",
    "\n",
    "def arr_to_str(arr):\n",
    "    return (arr[0])\n",
    "feature_vec_meta['sketch_id']=feature_vec_meta['sketch_id'].apply(arr_to_str)\n",
    "feature_vec_meta['target']=feature_vec_meta['target'].apply(arr_to_str)\n",
    "feature_vec_meta['condition']=feature_vec_meta['condition'].apply(arr_to_str)\n",
    "feature_vec_meta['category']=feature_vec_meta['category'].apply(arr_to_str)\n",
    "feature_vec_meta['outcome']=feature_vec_meta['outcome'].apply(arr_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df= pd.DataFrame(feature_vec, columns=[s + '_numstrokes' for s in valid_labels]+[s + '_total_arclength' for s in valid_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating a compressed version of the feature df with no duplicates for parts\n",
    "\n",
    "labs_numstrokes=[]\n",
    "labs_total_arclength=[]\n",
    "for lab in np.unique(valid_labels):\n",
    "    labs_numstrokes.append(lab +'_numstrokes')\n",
    "    labs_total_arclength.append(lab+'_total_arclength')\n",
    "feature_df_labs=labs_numstrokes+labs_total_arclength   \n",
    "feature_df_final= pd.DataFrame(columns=feature_df_labs)\n",
    "\n",
    "\n",
    "for this_lab in feature_df_labs:\n",
    "    duplicates=[col for col in feature_df if col.startswith(this_lab)]\n",
    "    feature_df_final[this_lab]= feature_df[duplicates].sum(axis=1)\n",
    "feature_df = feature_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check to make sure the df looks okay\n",
    "assert len(feature_df.columns)==len(np.unique(feature_df.columns))\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save out raw feature matrix prior to normalization within\n",
    "feature_df.to_csv(os.path.join(features_dir,'semantic_parts_sketch_features_compressed_rawcounts.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing within sketch, within measure (numstrokes/arclength) \n",
    "## Note: assumes that we are using two measures and that they account for exactly half of the columns in feature_df\n",
    "feature_df.iloc[:,0:int(len(feature_df.columns)/2)]=feature_df.iloc[:,0:int(len(feature_df.columns)/2)].div(feature_df.iloc[:,0:int(len(feature_df.columns)/2)].sum(axis=1),axis=0)\n",
    "feature_df.iloc[:,int(len(feature_df.columns)/2):int(len(feature_df.columns))]=feature_df.iloc[:,int(len(feature_df.columns)/2):int(len(feature_df.columns))].div(feature_df.iloc[:,int(len(feature_df.columns)/2):int(len(feature_df.columns))].sum(axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execute this if we want to save a non-zscore matrix\n",
    "run=True\n",
    "if run==True:\n",
    "    feature_df.to_csv(os.path.join(features_dir,'semantic_parts_sketch_features_compressed_normalized.csv'), index=False)\n",
    "run=False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-scoring within columns\n",
    "\n",
    "columns=list(feature_df.columns)\n",
    "for this_col in columns:\n",
    "    feature_df[this_col]=(feature_df[this_col] - feature_df[this_col].mean())/feature_df[this_col].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving out files as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(os.path.join(features_dir,'semantic_parts_sketch_features_compressed_normalized_whitened.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(features_dir, 'semantic_parts_sketch_features'),feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec_meta.to_csv(os.path.join(features_dir,'semantic_parts_sketch_meta.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_df(X):\n",
    "    if 'Unnamed: 0' in X.columns:\n",
    "        X = X.drop(columns=['Unnamed: 0'])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= cleanup_df(pd.read_pickle(os.path.join(csv_dir,'rawpckl')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.assignmentID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
