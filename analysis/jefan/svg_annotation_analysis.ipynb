{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "from svgpathtools import parse_path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)  \n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)  \n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))        \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up connection to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### set vars \n",
    "import pandas as pd\n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['semantic_parts']\n",
    "coll = db['sketchpad_basic']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'pilot0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get some descriptive stats on our annotation data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_annotations = coll.find({'iterationName':iterationName}).count()\n",
    "print 'We have {} annotations so far.'.format(num_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## get list of valid assignments\n",
    "unique_assignments = coll.find({'iterationName':iterationName}).distinct('aID')\n",
    "\n",
    "sketch_ids = []\n",
    "## construct list of unique sketches\n",
    "for this_aID in unique_assignments:\n",
    "    recs = coll.find({'$and': [{'iterationName':iterationName}, {'aID':this_aID}]}).sort('time')\n",
    "    for rec in recs:\n",
    "        print rec['originalGameID'], rec['originalTrialNum']\n",
    "        clear_output(wait=True)\n",
    "        sketch_ids.append('{}_{}'.format(rec['originalGameID'],str(rec['originalTrialNum']).zfill(2)))\n",
    "    \n",
    "print 'Finished constructing list of sketch IDs.'\n",
    "\n",
    "## visualize the number of sketches that have been annotated k times\n",
    "from collections import Counter\n",
    "h = plt.hist(Counter(sketch_ids).values())\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "plt.xlim(0,4.5)\n",
    "plt.ylim(0,1200)\n",
    "t = plt.xticks(np.arange(0,5,1))\n",
    "t = plt.ylabel('num sketches')\n",
    "t = plt.xlabel('num times annotated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check score for particular worker\n",
    "w = ''\n",
    "coll.find_one({ '$and': [{'iterationName':iterationName}, \\\n",
    "                        {'wID': w}]}, \\\n",
    "                        sort=[(\"bonus\", -1)])[\"bonus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build up annotation data csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO remember to ignore researcher worker ID's in our dataset\n",
    "jefan = ['A1MMCS8S8CTWKU','A1MMCS8S8CTWKV','A1MMCS8S8CTWKS']\n",
    "hawkrobe = ['A1BOIDKD33QSDK']\n",
    "megsano = ['A1DVQQLVZR7W6I']\n",
    "kmukherjee = ['A1WU4IHJNQGVAY']\n",
    "researchers = jefan + hawkrobe + megsano + kmukherjee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO use a helper function to get complete and valid HITs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## categories that are in play\n",
    "main_category = 'chair'\n",
    "dataset = 'chairs4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get list of unique_assignments\n",
    "unique_assignments = coll.find({'iterationName':iterationName}).distinct('aID')\n",
    "\n",
    "### initialize a bunch of stuff\n",
    "orig_gameID = [] # the gameID from which this sketch was sourced\n",
    "orig_trial_num = [] # the trialnum in the original game from which this sketch was sourced -- \n",
    "sketch_id = [] # concatenation of orig_gameID and orig_trial_num -- \n",
    "assignmentID = [] # the session in which this annotation was collected -- \n",
    "annotation_id = [] # the unique ID for each annotation trial (different for each session the same sketch appears in)\n",
    "category = [] # e.g., \"chair\"\n",
    "target = [] # e.g., \"inlay\"\n",
    "condition = [] # e.g., \"closer\" vs. \"further\" or \"repeated\" vs. \"control\n",
    "trial_num = []\n",
    "time_submitted = [] # when the participant clicked \"next sketch\"\n",
    "time_labeled = [] # unique to each spline labeled\n",
    "time_clicked = [] # when this spline was clicked/selected\n",
    "num_strokes_in_sketch = [] # how many strokes in this sketch\n",
    "num_splines_in_sketch = [] # how many spline elements in this sketch\n",
    "stroke_num = [] # which stroke number this labeled spline came from\n",
    "cumulative_spline_num = [] # spline index in the cumulative spline sequence for the entire sketch\n",
    "within_stroke_spline_num = [] # spline index for the current stroke\n",
    "label = [] # the label provided by the participant\n",
    "spline_svg_string = [] # the svg spline string that earned this label\n",
    "sketch_svg_string = [] # the entire svg string correponding to this sketch\n",
    "annotation_flag = [] # this is True if all splines were labeled as the same thing\n",
    "\n",
    "## loop through all the unique assignments that have submitted things\n",
    "for this_assignment, aID in enumerate(unique_assignments):\n",
    "    if this_assignment%50==0:\n",
    "        print 'Analyzing sketches from assignment {} of {}  ...'.format(this_assignment, len(unique_assignments))\n",
    "\n",
    "    ### get all the sketch recs for this assignment\n",
    "    sketch_recs = coll.find({'$and': [{'iterationName':iterationName}, {'aID':aID}]}).sort('time')\n",
    "\n",
    "    try:\n",
    "\n",
    "        for sketch_ind,sketch in enumerate(sketch_recs):\n",
    "            ## get annotations embedded within record\n",
    "            annotations_string = sketch['annotations']  \n",
    "            ## convert to json dictionary\n",
    "            _annotations_dict = json.loads(annotations_string)   \n",
    "            annotations_dict = _annotations_dict[0][main_category]\n",
    "            num_splines = len(annotations_dict)\n",
    "            for annotation in annotations_dict:\n",
    "                assert sketch['numSplines']==num_splines                \n",
    "                ## get spline-level metadata\n",
    "                label.append(annotation['label'])\n",
    "                stroke_num.append(annotation['strokeNum'])\n",
    "                spline_svg_string.append(annotation['svgString'])\n",
    "                cumulative_spline_num.append(annotation['cumulativeSplineNum'])\n",
    "                within_stroke_spline_num.append(annotation['withinStrokeSplineNum'])\n",
    "                time_clicked.append(annotation['timeClicked'])\n",
    "                time_labeled.append(annotation['timeLabeled'])\n",
    "                ## get sketch-level metadata\n",
    "                orig_gameID.append(sketch['originalGameID'])   \n",
    "                orig_trial_num.append(sketch['originalTrialNum'])\n",
    "                sketch_id.append('{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum']))\n",
    "                annotation_id.append('{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],sketch['aID']))\n",
    "                assignmentID.append(sketch['aID'])\n",
    "                category.append(sketch['category'])\n",
    "                target.append(sketch['target'])\n",
    "                condition.append(sketch['condition'])\n",
    "                time_submitted.append(sketch['time'])\n",
    "                trial_num.append(sketch['trialNum'])\n",
    "                num_splines_in_sketch.append(sketch['numSplines'])\n",
    "                num_strokes_in_sketch.append(sketch['numStrokes'])\n",
    "                sketch_svg_string.append(sketch['svg'])\n",
    "                annotation_flag.append(sketch['sameAnnotflag'])\n",
    "                \n",
    "    except AssertionError:\n",
    "        print 'There were unequal numbers for sketch[\"numSplines\"] vs. num_splines for sketch {} from {}'.\\\n",
    "                format(sketch['trialNum'], sketch['aID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make group data csv \n",
    "D = pd.DataFrame([orig_gameID, orig_trial_num, sketch_id, category, assignmentID,  target, \\\n",
    "                  annotation_id, condition, trial_num, time_submitted,\\\n",
    "                 time_labeled, time_clicked, num_strokes_in_sketch, num_splines_in_sketch,\\\n",
    "                 stroke_num, cumulative_spline_num, within_stroke_spline_num, label,\\\n",
    "                 spline_svg_string, sketch_svg_string])\n",
    "D = D.transpose()\n",
    "D.columns = ['orig_gameID', 'orig_trial_num', 'sketch_id', 'category', 'assignmentID', 'target',\\\n",
    "             'annotation_id', 'condition', 'trial_num', 'time_submitted',\\\n",
    "             'time_labeled', 'time_clicked', 'num_strokes_in_sketch', 'num_splines_in_sketch',\\\n",
    "             'stroke_num', 'cumulative_spline_num', 'within_stroke_spline_num', 'label',\\\n",
    "             'spline_svg_string', 'sketch_svg_string']\n",
    "D=D[D['assignmentID']!='']\n",
    "print 'Annotations dataframe contains {} rows and {} columns.'.format(D.shape[0],D.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save out csv to results dir\n",
    "D.to_csv(os.path.join(results_dir,'svg_annotations_{}.csv'.format(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### get descriptive stats on annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Some starting questions about sketchpad_basic dataset\n",
    "\n",
    "## Annotation task\n",
    "## How consistent are annotators for the same object? Inter-rater reliability\n",
    "\n",
    "## Content\n",
    "## What does the part distribution look like for each object? Presence/absence.\n",
    "## How does the part distribution differ between contexts, matched by object?\n",
    "\n",
    "## Contenty Style\n",
    "## Here we might use arc length as a measure of how much was expended for each part.\n",
    "## How much arc length is spent on each part \n",
    "## Is the entropy of the part distribution (measuring arc length) different for close trials than far trials?\n",
    "\n",
    "## Dynamics\n",
    "## Are people drawing each part \"in succession?\" (Do people plan & execute their drawings in terms of parts?)\n",
    "## Are people starting out producing longer strokes, than shorter strokes? Look at time series within \n",
    "## sketch for the arc lengths of strokes produced .... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Make visualizations of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How many sketches do we have annotated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_sketches = np.unique(D['sketch_id'].values)\n",
    "print 'We have {} unique sketches.'.format(len(unique_sketches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of times each sketch has been annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get number of times it has been annotated\n",
    "num_times_annotated = []\n",
    "for this_sketch_id in unique_sketches:\n",
    "    num_times_annotated.append(D[D['sketch_id']==this_sketch_id]['assignmentID'].nunique())\n",
    "    \n",
    "## make a histogram\n",
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(4,4))\n",
    "h = plt.hist(num_times_annotated)\n",
    "plt.title('# times each sketch has been annotated')\n",
    "plt.ylabel('number of sketches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check to make sure that for each sketch, you have a unique number of splines associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_sketches = np.unique(D['sketch_id'].values)\n",
    "for this_sketch in unique_sketches:\n",
    "    assert len(np.unique(D[D['sketch_id']==this_sketch]['num_splines_in_sketch'].values))==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How long do sketches take to annotate? Do more complex sketches (i.e., those consisting of more splines) take longer to annotate? [Sanity check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### first, we will get the amount of time taken to annotate each sketch\n",
    "unique_annotation_trials = np.unique(D['annotation_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get annotation time for each annotation trial\n",
    "annotation_time = []\n",
    "spline_number_in_sketch = []\n",
    "\n",
    "for this_annotation_trial in unique_annotation_trials:\n",
    "    earliest_click = float(np.min(D[D['annotation_id']==this_annotation_trial]['time_clicked']))\n",
    "    ## all of the splines were submitted at the same time, so time_submitted should be identical for all splines in an annotation trial\n",
    "    assert len(np.unique(D[D['annotation_id']==this_annotation_trial]['time_submitted'].values))==1\n",
    "    final_submission = np.unique(D[D['annotation_id']==this_annotation_trial]['time_submitted'].values)[0]\n",
    "    annotation_time.append(final_submission-earliest_click)        \n",
    "    if np.isnan(final_submission) or np.isnan(earliest_click):\n",
    "        print 'One of these timestamps is a NaN. Probably means that the participant skipped this trial:'\n",
    "        print this_annotation_trial\n",
    "        print 'final_submission: {}, earliest_click: {}'.format(final_submission, earliest_click)\n",
    "    #### then we will extract how \"complex\" each sketch i\n",
    "    assert len(np.unique(D[D['annotation_id']==this_annotation_trial]['num_splines_in_sketch'].values))==1    \n",
    "    spline_number_in_sketch.append(np.unique(D[D['annotation_id']==this_annotation_trial]['num_splines_in_sketch'])[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert annotation time to seconds\n",
    "annotation_time_seconds = np.array(annotation_time)/1000\n",
    "\n",
    "## make dataframe with annotation time and spline number\n",
    "unique_annotation_trials, spline_number_in_sketch, annotation_time_seconds = map(list, [unique_annotation_trials, spline_number_in_sketch, annotation_time_seconds])\n",
    "T = pd.DataFrame([unique_annotation_trials,spline_number_in_sketch,annotation_time_seconds])\n",
    "T = T.transpose()\n",
    "T.columns = ['annotation_trial','spline_number_in_sketch','annotation_time']\n",
    "\n",
    "## some preprocessing of T\n",
    "reload(h)\n",
    "\n",
    "## make numeric types\n",
    "T = h.convert_numeric(T,'spline_number_in_sketch')\n",
    "T = h.convert_numeric(T,'annotation_time')\n",
    "\n",
    "## also remove the skipped trial where annotation time is a NaN\n",
    "T = T[~np.isnan(T['annotation_time'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make scatterplot of relationship between annotation time and spline number\n",
    "sns.scatterplot(x='annotation_time',\n",
    "                y='spline_number_in_sketch',\n",
    "                data=T)\n",
    "plt.ylabel('spline number in sketch')\n",
    "plt.xlabel('annotation time (s)')\n",
    "plt.title('do more complex sketches take longer to annotate?')\n",
    "plt.xlim(0,60*5) ## 5 minute cutoff ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r, p = stats.spearmanr(T['annotation_time'],T['spline_number_in_sketch'])\n",
    "print 'Spearman correlation between annotation time and spline number in sketch' \n",
    "print 'r = {}, p = {}'.format(r,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Make histogram of part word occurrence distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get the list of unique labels applied to chairs\n",
    "unique_labels = np.unique(D.label.values)\n",
    "\n",
    "## some deborkification of the unique label list\n",
    "unique_labels = [i for i in unique_labels if i is not None]\n",
    "unique_labels = [i for i in unique_labels if len(i)<900]\n",
    "\n",
    "proper_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'After some light deborkificiation, there are {} unique part labels in our dataset.'.format(len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create a dataframe that is [num_sketches x num_labels] where each cell is incremented by 1\n",
    "## when that part word appears as an annotation to that sketch\n",
    "unique_labels = np.array(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## initialize matrix that has the correct dimensions\n",
    "Label_Vec = np.zeros((len(unique_sketches),len(unique_labels)), dtype=int)\n",
    "\n",
    "for s,this_sketch in enumerate(unique_sketches):\n",
    "    label_vec = np.zeros(len(unique_labels),dtype=int)\n",
    "    DS = D[D['sketch_id']==this_sketch]\n",
    "    annotation_ids = np.unique(DS['annotation_id'].values)    \n",
    "    for this_annotation in annotation_ids:\n",
    "        DSA = DS[(DS['sketch_id']==this_sketch) & (DS['annotation_id']==this_annotation)]\n",
    "        label_list = np.unique(DSA.label.values)\n",
    "        for this_label in label_list:\n",
    "            label_ind = unique_labels==this_label\n",
    "            label_vec[label_ind] += 1\n",
    "    Label_Vec[s,:]=label_vec                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = 100\n",
    "print 'These are the labels that appear at least {} times:'.format(thresh)\n",
    "print unique_labels[np.sum(Label_Vec,0)>thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### read in stroke dataframe in order to get part distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strokes = pd.read_csv(os.path.join(results_dir,'stroke_df_lite.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strokes.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = strokes.groupby(['condition','sketch_id'])['stroke_num'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = A.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = np.array([['a',1],['b',2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "where= np.where(array=='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(array[where[0],where[1]+1].item())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
