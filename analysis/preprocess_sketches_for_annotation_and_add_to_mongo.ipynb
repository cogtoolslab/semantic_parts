{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib as mp\n",
    "from matplotlib import pyplot,pylab\n",
    "plt = pyplot\n",
    "import scipy\n",
    "from __future__ import division\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "import string\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "\n",
    "import json\n",
    "import pymongo as pm\n",
    "\n",
    "from svgpathtools import parse_path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* upload sketches to S3 [maybe do this later]\n",
    "* build stimulus dictionary and write to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upload sketches to S3 [todo later]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build stimulus dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## read in experimental metadata file (CSV)\n",
    "path_to_metadata = 'sketchpad_basic_allcats.csv'\n",
    "_meta = pd.read_csv(path_to_metadata)   ### raw meta with all categories\n",
    "\n",
    "## subset by chairs\n",
    "meta_chairs = _meta[_meta['category']=='chair'] ### subsetted meta with just chairs\n",
    "\n",
    "## TODO: what we actually want Make sure that the data we're excluding from annotation \n",
    "## really the come from the trials where we had the shift-key artifact. \n",
    "## Right now, we are excluding sketches with numStrokes > mu + 3*sd, which is an imperfect proxy for that.\n",
    "mu = np.mean(meta_chairs['numStrokes'])\n",
    "sd = np.std(meta_chairs['numStrokes'])\n",
    "thresh = mu + 3*sd\n",
    "meta_chairs = meta_chairs[meta_chairs['numStrokes']<thresh]\n",
    "meta_chairs.reset_index(inplace=True) ## reset index on meta_chairs\n",
    "\n",
    "## sub-select good 4 chairs\n",
    "## inlay>waiting>straight>leather\n",
    "chairs4_list = ['inlay','waiting','straight','leather']\n",
    "meta_chairs4 = meta_chairs[meta_chairs['target'].isin(chairs4_list)]\n",
    "meta_chairs4.reset_index(inplace=True)\n",
    "\n",
    "## assign which meta we will actually upload to mongo in this session\n",
    "category_flag = 'chairs4' ## options: ['allcats','chairs','chairs4']\n",
    "\n",
    "if category_flag == 'chairs':\n",
    "    meta = meta_chairs\n",
    "elif category_flag == 'chairs4':\n",
    "    meta = meta_chairs4\n",
    "elif category_flag == 'allcats':\n",
    "    meta = _meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add parts list\n",
    "parts =[]\n",
    "for i in range(meta.shape[0]-1):\n",
    "    if meta.category[i]==\"chair\":\n",
    "        parts.append([\"backrest,armrest,seat,leg\"])        \n",
    "    if meta.category[i]==\"dog\":\n",
    "        parts.append([\"eye,mouth,ear,head,neck,body,leg,tail\"])\n",
    "    if meta.category[i] == \"bird\":\n",
    "        parts.append([\"beak,head,body,wings,feet,tail\"])\n",
    "    if meta.category[i] == \"car\":\n",
    "        parts.append([\"bumper,lights,windshield,body,window,door,wheel\"])\n",
    "meta = meta.assign(parts=pd.Series(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add iteration name information\n",
    "_iterationName = 'sketchpad_basic_{}'.format(category_flag)\n",
    "iterationName = [_iterationName]*len(meta)\n",
    "meta = meta.assign(iterationName=pd.Series(iterationName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## svg string formatting\n",
    "svg = []\n",
    "for i,d in meta.iterrows():    \n",
    "    splitted = d['svg'].split(\"'\") ## parse string to re-split up into strokes\n",
    "    svgString = [i for i in splitted if i[0]=='M'] ## check to make sure it is a real start of a spline\n",
    "    svg.append(svgString)\n",
    "meta = meta.assign(svg=pd.Series(svg)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add numSplines to the meta data\n",
    "numSplines = []\n",
    "for sketch in sketch_svgs:\n",
    "    num_splines = 0\n",
    "    for stroke_ind,stroke in enumerate(sketch):\n",
    "        parsed = parse_path(stroke)\n",
    "        num_splines += len(parsed)\n",
    "    numSplines.append(num_splines)\n",
    "meta = meta.assign(numSplines=pd.Series(numSplines))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add empty games list\n",
    "games = [[] for i in np.arange(len(meta))]\n",
    "meta = meta.assign(games=pd.Series(games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## how many games worth of data do we have?\n",
    "print '{} unique games worth of data.'.format(len(np.unique(meta.gameID.values)))\n",
    "print '{} unique sketches.'.format(len(meta))\n",
    "\n",
    "## write out metadata to json file\n",
    "\n",
    "## for example:\n",
    "stimdict = meta.to_dict(orient='records')\n",
    "stimdict\n",
    "import json\n",
    "with open('annotation_meta.js', 'w') as fout:\n",
    "     json.dump(stimdict, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interlude to examine detailed statistics on constituent splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## svg is a list of sketches\n",
    "## each entry contains a list of strokes\n",
    "## first let's convert into absolute coordinates\n",
    "## then let's convert these into a list of splines that are \"long enough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_relative_spline_to_absolute(parsed):\n",
    "    svg_abs = ''\n",
    "    for i,p in enumerate(parsed):\n",
    "        if len(p)==4: ## cubic bezier\n",
    "            svg_abs += ' M '\n",
    "            svg_abs += '{},{}'.format(str(p.start.real),str(p.start.imag))\n",
    "            svg_abs += ' C'\n",
    "            svg_abs += ' {},{}'.format(str(p.control1.real),str(p.control1.imag))\n",
    "            svg_abs += ' {},{}'.format(str(p.control2.real),str(p.control2.imag))\n",
    "            svg_abs += ' {},{}'.format(str(p.end.real),str(p.end.imag)) \n",
    "        if len(p)==2: ## line segment\n",
    "            svg_abs += ' M '\n",
    "            svg_abs += '{},{}'.format(str(p.start.real),str(p.start.imag))\n",
    "            svg_abs += ' L'\n",
    "            svg_abs += ' {},{}'.format(str(p.end.real),str(p.end.imag))          \n",
    "#     assert np.all(np.round(parsed)==np.round(parse_path(svg_abs)))==True\n",
    "    return svg_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get list of sketch svg converted to absolute coordinates\n",
    "## grouped into **strokes**\n",
    "svg_abs_strokes = []\n",
    "for this_sketch in svg:\n",
    "    sketch_abs = []\n",
    "    for this_stroke in this_sketch:  \n",
    "        this_stroke = this_stroke.replace('v0','') ## eliminate single points\n",
    "        this_stroke = this_stroke.replace('h0','') ## eliminate single points\n",
    "        parsed = parse_path(this_stroke)\n",
    "        parsed_abs = convert_relative_spline_to_absolute(parsed)\n",
    "        sketch_abs.append(parsed_abs)\n",
    "    svg_abs_strokes.append(sketch_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get list of sketch svg converted to absolute coordinates\n",
    "## grouped into **splines**\n",
    "svg_abs_splines = [] \n",
    "stroke_num_within_sketch = [] ## get stroke num within sketch\n",
    "for this_sketch in svg_abs_strokes:\n",
    "    sketch_abs = []\n",
    "    _stroke_num_within_sketch = []    \n",
    "    for stroke_id,this_stroke in enumerate(this_sketch):\n",
    "        this_path = parse_path(this_stroke)\n",
    "        for i,p in enumerate(this_path):\n",
    "            _svg_abs = ''\n",
    "            if len(p)==4: ## cubic bezier\n",
    "                _svg_abs += ' M '\n",
    "                _svg_abs += '{},{}'.format(str(p.start.real),str(p.start.imag))\n",
    "                _svg_abs += ' C'\n",
    "                _svg_abs += ' {},{}'.format(str(p.control1.real),str(p.control1.imag))\n",
    "                _svg_abs += ' {},{}'.format(str(p.control2.real),str(p.control2.imag))\n",
    "                _svg_abs += ' {},{}'.format(str(p.end.real),str(p.end.imag)) \n",
    "            if len(p)==2: ## line segment\n",
    "                _svg_abs += ' M '\n",
    "                _svg_abs += '{},{}'.format(str(p.start.real),str(p.start.imag))\n",
    "                _svg_abs += ' L'\n",
    "                _svg_abs += ' {},{}'.format(str(p.end.real),str(p.end.imag))  \n",
    "            sketch_abs.append(_svg_abs)\n",
    "            _stroke_num_within_sketch.append(stroke_id)\n",
    "    svg_abs_splines.append(sketch_abs)\n",
    "    stroke_num_within_sketch.append(_stroke_num_within_sketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create list of spline arc lengths nested in the same way as svg_abs_splines\n",
    "svg_abs_spline_lengths = []\n",
    "for sketch_ind,this_sketch in enumerate(svg_abs_splines):\n",
    "    sketch_abs_length = []\n",
    "    for spline_ind,spline in enumerate(this_sketch):\n",
    "        curr_stroke_ind = stroke_num_within_sketch[sketch_ind][spline_ind]    \n",
    "        curr_spline_length = parse_path(spline).length()\n",
    "        sketch_abs_length.append(curr_spline_length)\n",
    "    svg_abs_spline_lengths.append(sketch_abs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    return [item for sublist in x for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get all spline lengths\n",
    "flat_spline_lengths = flatten(svg_abs_spline_lengths)\n",
    "\n",
    "## make figure\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.set_context('paper')\n",
    "plt.title('Distribution of spline arc lengths across all sketches')\n",
    "plt.hist(flat_spline_lengths,200)\n",
    "plt.xticks(np.linspace(0,200,51))\n",
    "plt.xlim(0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload stim dictionary to mongo (db = 'stimuli', collection='sketchpad_basic_recog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## do you want to upload a \"development mode\" collection for testing?\n",
    "dev_mode = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load in the JSON that contains the svgData, object labels, and part labels\n",
    "J = json.loads(open('annotation_meta.js',mode='ru').read())\n",
    "assert len(J)==len(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define the dbname and collection name\n",
    "db = conn['stimuli']\n",
    "if dev_mode:\n",
    "    coll = db['svg_annotation_sketchpad_basic_{}_dev'.format(category_flag)]\n",
    "else:\n",
    "    coll = db['svg_annotation_sketchpad_basic_{}'.format(category_flag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## actually add data now to the database (iff reallyRun==True)\n",
    "reallyRun = True\n",
    "if reallyRun:\n",
    "    for (i,j) in enumerate(J):\n",
    "        if i%250==0:\n",
    "            print ('%d of %d' % (i,len(J)))\n",
    "        coll.insert_one(j)\n",
    "reallyRun = False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## How many sketches do we have in the database?\n",
    "print 'We have {} sketches.'.format(coll.count())\n",
    "\n",
    "## What kind of sketches do we have in the database?\n",
    "print 'We have these kinds: {}'.format(str(coll.distinct('category')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
