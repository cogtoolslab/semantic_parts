{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "features_dir= os.path.join(results_dir,'features')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)  \n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(features_dir):\n",
    "    os.makedirs(features_dir)\n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))        \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_df(X):\n",
    "    if 'Unnamed: 0' in X.columns:\n",
    "        X = X.drop(columns=['Unnamed: 0'])\n",
    "    return X\n",
    "\n",
    "def flatten(x):\n",
    "    return [item for sublist in x for item in sublist]\n",
    "\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper dictionaries \n",
    "OBJECT_TO_CATEGORY = {\n",
    "    'basset': 'dog', 'beetle': 'car', 'bloodhound': 'dog', 'bluejay': 'bird',\n",
    "    'bluesedan': 'car', 'bluesport': 'car', 'brown': 'car', 'bullmastiff': 'dog',\n",
    "    'chihuahua': 'dog', 'crow': 'bird', 'cuckoo': 'bird', 'doberman': 'dog',\n",
    "    'goldenretriever': 'dog', 'hatchback': 'car', 'inlay': 'chair', 'knob': 'chair',\n",
    "    'leather': 'chair', 'nightingale': 'bird', 'pigeon': 'bird', 'pug': 'dog',\n",
    "    'redantique': 'car', 'redsport': 'car', 'robin': 'bird', 'sling': 'chair',\n",
    "    'sparrow': 'bird', 'squat': 'chair', 'straight': 'chair', 'tomtit': 'bird',\n",
    "    'waiting': 'chair', 'weimaraner': 'dog', 'white': 'car', 'woven': 'chair',\n",
    "}\n",
    "CATEGORY_TO_OBJECT = {\n",
    "    'dog': ['basset', 'bloodhound', 'bullmastiff', 'chihuahua', 'doberman', 'goldenretriever', 'pug', 'weimaraner'],\n",
    "    'car': ['beetle', 'bluesedan', 'bluesport', 'brown', 'hatchback', 'redantique', 'redsport', 'white'],\n",
    "    'bird': ['bluejay', 'crow', 'cuckoo', 'nightingale', 'pigeon', 'robin', 'sparrow', 'tomtit'],\n",
    "    'chair': ['inlay', 'knob', 'leather', 'sling', 'squat', 'straight', 'waiting', 'woven'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading in files we need\n",
    "dataset = 'rawcounts'\n",
    "feature_df = cleanup_df(pd.read_csv(os.path.join(features_dir,'semantic_parts_sketch_features_compressed_{}.csv'.format(dataset))))\n",
    "meta_df = cleanup_df(pd.read_csv(os.path.join(features_dir,'semantic_parts_sketch_meta.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sanity check: make sure that the numstrokes and arclength features each add up to 1\n",
    "numstrokes_cols = [i for i in feature_df.columns if i.split('_')[-1]=='numstrokes']\n",
    "arclength_cols = [i for i in feature_df.columns if i.split('_')[-1]=='arclength']\n",
    "if dataset=='normalized':\n",
    "    assert len(np.unique(feature_df[arclength_cols].sum(axis=1).round(10)))==1\n",
    "    assert len(np.unique(feature_df[numstrokes_cols].sum(axis=1).round(10)))==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize feature_df (apply whitening)? \n",
    "## Warning, this will make it so numstrokes and arclength features DO NOT add up to 1\n",
    "whitening = True\n",
    "if whitening:\n",
    "    feature_df = normalize(feature_df)\n",
    "    print 'Applied whitening to raw feature matrix.'\n",
    "else:\n",
    "    print 'Did not apply whitening to raw feature matrix.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate meta and features to enable easy subsetting of dataframe\n",
    "F = pd.concat((meta_df,feature_df),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregate by (object, context-condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate by target and condition and take the mean across rows within each group\n",
    "F2 = F.groupby(['target','condition']).mean().reset_index()\n",
    "\n",
    "## get ordered list of all objects\n",
    "obj_list = np.unique(F.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## re-add category back to the F2 dataframe so we can subset on that later\n",
    "F2['category'] = F2['target'].apply(lambda x: OBJECT_TO_CATEGORY[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subset by context condition and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get names of columns that contain stroke-count & arclength information\n",
    "numstrokes_cols = [i for i in feature_df.columns if i.split('_')[-1]=='numstrokes']\n",
    "arclength_cols = [i for i in feature_df.columns if i.split('_')[-1]=='arclength']\n",
    "feat_cols = numstrokes_cols + arclength_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define scope of comparison\n",
    "def subset_dataframe_by_condition(F,to_inspect='all',this_category='dog',this_object='pug'):\n",
    "    '''\n",
    "    input: F: dataframe (num_sketches x num_features)\n",
    "           to_inspect: a string indicating whether to subset by ['object','category','all']\n",
    "           this_category: IF to_inspect == 'category', then we define this to subset by that category only\n",
    "           this_object: IF to_inspect == 'object', then we define this to subset by that object only\n",
    "           \n",
    "    returns: two feature matrices, c and f, corresponding to the close and far subsetted feature matrices\n",
    "           \n",
    "    '''\n",
    "        \n",
    "    ## get context condition inds for subsetting dataframe\n",
    "    close_inds = F['condition'] == 'closer'\n",
    "    far_inds = F['condition'] == 'further'\n",
    "\n",
    "    ## if we want to inspect particular category\n",
    "    category_inds = F['category']==this_category\n",
    "\n",
    "    ## if we want to inspect particular object\n",
    "    obj_list = np.unique(F.target.values)\n",
    "    obj_inds = F['target']==this_object  \n",
    "    \n",
    "    ## get names of columns that contain stroke-count & arclength information\n",
    "    numstrokes_cols = [i for i in F.columns if i.split('_')[-1]=='numstrokes']\n",
    "    arclength_cols = [i for i in F.columns if i.split('_')[-1]=='arclength']\n",
    "    feat_cols = numstrokes_cols + arclength_cols\n",
    "    \n",
    "    if to_inspect == 'object':    \n",
    "        ## extract particular row corresponding to this OBJECT in each condition\n",
    "        f = F[(far_inds) & obj_inds][feat_cols].reset_index(drop=True)\n",
    "        c = F[(close_inds) & obj_inds][feat_cols].reset_index(drop=True)\n",
    "    elif to_inspect == 'category':\n",
    "        ## extract particular rows corresponding to this CATEGORY in each condition\n",
    "        f = F[(category_inds) & (far_inds)][feat_cols].reset_index(drop=True)\n",
    "        c = F[(category_inds) & (close_inds)][feat_cols].reset_index(drop=True)\n",
    "    elif to_inspect == 'all':\n",
    "        ## extract particular rows corresponding to this CATEGORY in each condition\n",
    "        f = F[far_inds][feat_cols].reset_index(drop=True)\n",
    "        c = F[close_inds][feat_cols].reset_index(drop=True) \n",
    "    return c, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing close vs. far sketch dispersion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_inspect = 'category'\n",
    "this_category = 'dog'\n",
    "c,f = subset_dataframe_by_condition(F2,\n",
    "                                    to_inspect=to_inspect,\n",
    "                                    this_category=this_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stack the close and far feature matrices to get (16 x K) feature matrix\n",
    "fmat = np.vstack((np.array(c),np.array(f)))\n",
    "\n",
    "## sanity check to make sure there are a total of 16 rows b/c there are 8 objects x 2 context conditions \n",
    "if to_inspect=='category':\n",
    "    assert np.vstack((np.array(c),np.array(f))).shape[0] == 16\n",
    "elif to_inspect=='all':\n",
    "    assert np.vstack((np.array(c),np.array(f))).shape[0] == 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## produce visualization of matrix\n",
    "from sklearn.metrics import *\n",
    "sns.set_style('white')\n",
    "D = pairwise_distances(fmat,metric='euclidean')\n",
    "plt.matshow(D)\n",
    "plt.plot((7.5, 7.5), (-0.5, 15.5), 'k-') # vertical refline\n",
    "plt.plot((-0.5, 15.5), (7.5, 7.5), 'k-') # horizontal refline\n",
    "plt.colorbar(fraction=0.05)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('close          far')\n",
    "plt.ylabel('far          close')\n",
    "plt.title('object distances x condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refresher on properties of variance\n",
    "https://en.wikipedia.org/wiki/Variance\n",
    "\n",
    "$ \\operatorname{Var}(X) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^2 $\n",
    "\n",
    "$ \\operatorname{Var}(X) = \\frac{1}{n^2} \\sum_{i=1}^n \\sum_{j=1}^n \\frac{1}{2}(x_i - x_j)^2 = \\frac{1}{n^2}\\sum_i \\sum_{j>i} (x_i-x_j)^2. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each category, compare the within-condition variance \n",
    "## and the length of the centroid vector \n",
    "to_inspect = 'category'\n",
    "dist_metric = 'euclidean'\n",
    "categories = ['bird','car','chair','dog']\n",
    "\n",
    "for i, this_category in enumerate(categories):\n",
    "    c,f = subset_dataframe_by_condition(F2,\n",
    "                                        to_inspect=to_inspect,\n",
    "                                        this_category=this_category) ## get subset of features\n",
    "\n",
    "    fmat = np.vstack((np.array(c),np.array(f))) ## stack\n",
    "    D = pairwise_distances(fmat,metric=dist_metric) ## get distances\n",
    "    dim = D.shape[0]\n",
    "    half_dim = int(dim/2)\n",
    "    triu_inds = np.triu_indices(half_dim,k=1)\n",
    "\n",
    "    ## get pairwise distances between objects within context condition\n",
    "    close_pairwise_dists = D[:half_dim,:half_dim][triu_inds]\n",
    "    far_pairwise_dists = D[half_dim:dim,half_dim:dim][triu_inds]\n",
    "\n",
    "\n",
    "    ## get euclidean distances of each object from origin \n",
    "    frob_c = np.apply_along_axis(np.linalg.norm,1,c)\n",
    "    frob_f = np.apply_along_axis(np.linalg.norm,1,f)\n",
    "\n",
    "    ## get std and mean distance from zero for each condition\n",
    "    far_std = np.mean(far_pairwise_dists)\n",
    "    far_mean = np.mean(frob_f)\n",
    "\n",
    "    close_std = np.mean(close_pairwise_dists)\n",
    "    close_mean = np.mean(frob_c)\n",
    "\n",
    "    ## compute coefficient of variation, \n",
    "    ## measure of what percentage of the mean the dispersion is ...co\n",
    "    ## if low, indicates higher mean relative to variance\n",
    "    ## if high, indicates higher variance relative to mean\n",
    "    ## https://en.wikipedia.org/wiki/Coefficient_of_variation\n",
    "    far_cv = far_std/far_mean\n",
    "    close_cv = close_std/close_mean\n",
    "    print 'Category: {} | CV for close: {}, CV for far: {}.'.format(this_category, close_cv.round(3), far_cv.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lower CV for far indicates tighter distribution, even accounting for distance from origin.\n",
    "    That is, far sketches are more similar to each other than close sketches are to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### characterize \"context difference vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "     return [item for sublist in x for item in sublist]\n",
    "    \n",
    "def get_ordered_objs_list_by_category(F):\n",
    "    objs_list = []\n",
    "    close_inds = F['condition'] == 'closer'\n",
    "    far_inds = F['condition'] == 'further'\n",
    "    categories = ['bird','car','chair','dog']\n",
    "    for this_category in categories:\n",
    "        category_inds = F['category'] == this_category\n",
    "        objs_list.append(list(F[(category_inds) & (far_inds)].reset_index(drop=True).target.values))\n",
    "    return flatten(objs_list)\n",
    "\n",
    "ordered_objs = get_ordered_objs_list_by_category(F2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get difference between close and far\n",
    "to_inspect = 'category'\n",
    "categories = ['bird','car','chair','dog']\n",
    "this_category = categories[0]\n",
    "d = []\n",
    "for i, this_category in enumerate(categories):\n",
    "    c,f = subset_dataframe_by_condition(F2,\n",
    "                                        to_inspect=to_inspect,\n",
    "                                        this_category=this_category) ## get subset of features\n",
    "\n",
    "    _d = c.sub(f)\n",
    "    if len(d)==0:\n",
    "        d = _d\n",
    "    else:\n",
    "        d = pd.concat((d,_d),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize how well aligned the difference vectors are within a category\n",
    "dist_metric = 'correlation'\n",
    "D = 1 - pairwise_distances(d,metric=dist_metric)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.matshow(D, cmap=plt.cm.Spectral,vmin=-1.,vmax=1.)\n",
    "plt.colorbar(fraction=0.04)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "t = plt.xticks(range(len(ordered_objs)), ordered_objs, fontsize=10,rotation='vertical')\n",
    "t = plt.yticks(range(len(ordered_objs)), ordered_objs, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seems to be that for two of the categories, the difference vectors are all highly correlated with each other (bird, car), but this is less apparent for two of the other categories (chair, dog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measuring relative \"spikiness\" in close vs. far sketches?\n",
    "Perhaps using Frobenius norm (root sum squares of each element in the vector),\n",
    " which is minimized for uniform vector, and larger for spikier vectors (with larger values concentrated in fewer dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpers\n",
    "def entropy(probs):    \n",
    "    return - 1 * sum(map(lambda x: x * np.log(x),probs))\n",
    "\n",
    "def KL_div_uniform(probs):\n",
    "    unif_p = 1/len(probs)\n",
    "    return sum(map(lambda x: unif_p * np.log(unif_p/x),probs))\n",
    "\n",
    "def softmax(X):\n",
    "    '''\n",
    "    input: X is a (1 x N) array\n",
    "    output: 1 x N array\n",
    "    '''\n",
    "    return np.exp(X)/np.sum(np.exp(X))\n",
    "\n",
    "\n",
    "def minmaxscale(X):\n",
    "\n",
    "    return (X-np.min(X))/(np.max(X)-np.min(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract just the feature columns of the feature matrix, and break out by context \n",
    "to_inspect = 'all'\n",
    "c,f = subset_dataframe_by_condition(F2,to_inspect=to_inspect)\n",
    "\n",
    "## convert to numpy array\n",
    "c = np.array(c)\n",
    "f = np.array(f)\n",
    "\n",
    "scale_mode='minmax'  ## minmax or softmax\n",
    "\n",
    "if scale_mode == 'softmax':\n",
    "    ## softmax\n",
    "    soft_c = np.apply_along_axis(softmax,1,c)\n",
    "    soft_f = np.apply_along_axis(softmax,1,f)\n",
    "    ## get \"spikiness\" index on close and far average sketches for each object\n",
    "    close_norm = np.apply_along_axis(np.linalg.norm,1,soft_c)\n",
    "    far_norm = np.apply_along_axis(np.linalg.norm,1,soft_f)\n",
    "    diff_norm = close_norm - far_norm  \n",
    "elif scale_mode == 'minmax':\n",
    "    ##minmax\n",
    "\n",
    "    minmax_c = np.apply_along_axis(minmaxscale,1,c)\n",
    "    minmax_f = np.apply_along_axis(minmaxscale,1,f)\n",
    "    ## get \"spikiness\" index on close and far average sketches for each object\n",
    "    close_norm = np.apply_along_axis(np.linalg.norm,1,minmax_c)\n",
    "    far_norm = np.apply_along_axis(np.linalg.norm,1,minmax_f)\n",
    "    diff_norm = close_norm - far_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(diff_norm)\n",
    "print 'Mean close spikiness = {}  (higher values are spikier)'.format(np.mean(close_norm).round(4))\n",
    "print 'Mean far spikiness = {}'.format(np.mean(far_norm).round(4))\n",
    "print 'Mean close-far difference on spikiness = {}'.format(np.mean(diff_norm).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = sum(np.array(diff_norm)>0)\n",
    "print 'Number of objects for which close was spikier than far: {}'.format(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_soft_c= np.mean(soft_c,0)\n",
    "mean_soft_f = np.mean(soft_f,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = plt.plot(soft_c[1,:].T,label='close')\n",
    "l = plt.plot(soft_f[1,:].T,label='far')\n",
    "plt.legend()\n",
    "plt.xlabel('feature dim')\n",
    "plt.ylabel('softmax feature weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = plt.plot(minmax_c[0,:].T,label='close')\n",
    "l = plt.plot(minmax_f[0,:].T,label='far')\n",
    "plt.legend()\n",
    "plt.xlabel('feature dim')\n",
    "plt.ylabel('minmax feature weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Looks like the pattern of peaks might be preserved between close and far, just taller peaks for close, \n",
    "## but rank ordering of peaks is preserved? If that is the case, then we predict that the Spearman correlation \n",
    "## coefficient will be high between close and far vectors for each object... \n",
    "import scipy.stats\n",
    "    \n",
    "for i in range(32):\n",
    "    plt.figure()\n",
    "    s = plt.scatter(soft_c[i,:],soft_f[i,:])\n",
    "    plt.title(stats.spearmanr(soft_c[i,:],soft_f[i,:]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = plt.scatter(minmax_c[0,:],minmax_f[0,:])\n",
    "import scipy.stats\n",
    "print stats.spearmanr(minmax_c[0,:],minmax_f[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip(obj_list,diff_norm,np.arange(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### relationship between numstrokes and arclength features in unaggregated feature matrix (at sketch level)\n",
    "I.e., Check how redundant the num strokes vector is with the arclength vector across sketches (how correlated are the 23 vectors across sketches within an object?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "if dataset=='normalized':\n",
    "    assert len(np.unique(F[arclength_cols].sum(axis=1).round(10)))==1\n",
    "    assert len(np.unique(F[numstrokes_cols].sum(axis=1).round(10)))==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inspect particular category\n",
    "this_category = 'chair'\n",
    "category_inds = F['category']==this_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract matrix form of just the arclength and numstrokes columns\n",
    "to_inspect = 'all'\n",
    "if to_inspect == 'category':\n",
    "    arcF = np.array(F[category_inds][arclength_cols])\n",
    "    numF = np.array(F[category_inds][numstrokes_cols])\n",
    "elif to_inspect == 'all':\n",
    "    arcF = np.array(F[arclength_cols])\n",
    "    numF = np.array(F[numstrokes_cols])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a sense for how correspondent the numstrokes and arclength features are (how redundant are they?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get distances between sketches using either numstrokes (numF) or arclength (arcF)\n",
    "feat_type = numF\n",
    "D = pairwise_distances(feat_type,metric='euclidean')\n",
    "dists_within_metric = D[np.triu_indices(D.shape[0], k=1)]\n",
    "print 'Mean euclidean distance between sketches using a single metric (numstrokes or arclength): {}'.format(np.mean(dists_within_metric).round(5))\n",
    "\n",
    "## get correspondence between numstrokes and arclength feature\n",
    "dists_btw_metrics = [distance.euclidean(arcV,numV) for(arcV, numV) in zip(arcF,numF)]\n",
    "print 'Mean euclidean distance within sketches between arclength and numstrokes feature vectors: {}'.format(np.mean(dists_btw_metrics).round(5))\n",
    "\n",
    "## get distance between randomly sampled numstroke and arclength vector from different sketches\n",
    "nIter = 1000\n",
    "num_sketches = np.shape(arcF)[0]\n",
    "dists_btw_metrics_permuted = []\n",
    "for this_iter in np.arange(nIter):\n",
    "    rand_inds = np.random.RandomState(this_iter).choice(num_sketches,2)\n",
    "    arcV = arcF[rand_inds[0],:]\n",
    "    numV = numF[rand_inds[1],:]\n",
    "    dists_btw_metrics_permuted.append(distance.euclidean(arcV,numV))\n",
    "print \"Mean euclidean distance between randomly sampled sketches' arclength and numstrokes feature vectors: {}\".format(np.mean(dists_btw_metrics_permuted).round(5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hmm, maybe a better way to do this. How about learning linear mapping from numstrokes to arclength and computing variance explained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assume linear function to map from X to y\n",
    "## y = Xb\n",
    "X = arcF \n",
    "y = numF\n",
    "\n",
    "## solve for b directly using pseudo inverse\n",
    "b = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "yhat = X.dot(b)\n",
    "\n",
    "## get proportion of variance explained\n",
    "## https://en.wikipedia.org/wiki/Fraction_of_variance_unexplained\n",
    "## Fraction of variance unexplained, FVU = SS_err / SS_tot\n",
    "SS_err = np.sum([distance.euclidean(_yhat,_y)**2 for (_yhat, _y) in zip(yhat,y)])\n",
    "SS_tot = np.sum([distance.euclidean(_y,y.mean(0))**2 for _y in y])\n",
    "FVU = SS_err / SS_tot\n",
    "print 'Fraction of variance unexplained after learning linear mapping to arclength to get numstrokes is: {}.'.format(FVU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
