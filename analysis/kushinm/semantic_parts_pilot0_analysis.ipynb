{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "from svgpathtools import parse_path\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up and creating dataframe for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "features_dir= os.path.join(results_dir,'features')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)  \n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)  \n",
    "\n",
    "if not os.path.exists(features_dir):\n",
    "    os.makedirs(features_dir)\n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))        \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up connection to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "key  = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['semantic_parts']\n",
    "coll = db['sketchpad_basic']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'pilot0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sketches = coll.find({'iterationName':iterationName}).count()\n",
    "print 'We have {} annotations so far.'.format(num_sketches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jefan = ['A1MMCS8S8CTWKU','A1MMCS8S8CTWKV','A1MMCS8S8CTWKS']\n",
    "hawkrobe = ['A1BOIDKD33QSDK']\n",
    "kmukherjee = ['A1WU4IHJNQGVAY']\n",
    "researchers = jefan + hawkrobe  + kmukherjee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_assignments = coll.find({'iterationName':iterationName}).distinct('aID')\n",
    "print 'We have had {} unique sessions'.format( len(unique_assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## get list of unique_assignments\n",
    "unique_assignments = coll.find({'iterationName':iterationName}).distinct('aID')\n",
    "\n",
    "### initialize a bunch of stuff\n",
    "orig_gameID = [] # the gameID from which this sketch was sourced\n",
    "outcome =[] #original outcome for that trial- true/false\n",
    "orig_trial_num = [] # the trialnum in the original game from which this sketch was sourced -- \n",
    "sketch_id = [] # concatenation of orig_gameID and orig_trial_num -- \n",
    "assignmentID = [] # the session in which this annotation was collected -- \n",
    "annotation_id = [] # the unique ID for each annotation trial (different for each session the same sketch appears in)\n",
    "category = [] # e.g., \"chair\"\n",
    "target = [] # e.g., \"inlay\"\n",
    "condition = [] # e.g., \"closer\" vs. \"further\" or \"repeated\" vs. \"control\n",
    "trial_num = [] \n",
    "workerID = [] #mTurk workerId\n",
    "spline_id =[] #unique spline identifier\n",
    "time_submitted = [] # when the participant clicked \"next sketch\"\n",
    "time_labeled = [] # unique to each spline labeled\n",
    "time_clicked = [] # when this spline was clicked/selected\n",
    "num_strokes_in_sketch = [] # how many strokes in this sketch\n",
    "num_splines_in_sketch = [] # how many spline elements in this sketch\n",
    "stroke_num = [] # which stroke number this labeled spline came from\n",
    "cumulative_spline_num = [] # spline index in the cumulative spline sequence for the entire sketch\n",
    "within_stroke_spline_num = [] # spline index for the current stroke\n",
    "cumulative_bout_num= [] #which bout of annotation the spline belonged to\n",
    "part_bout_num =[] #which part-specific bout of annotation the spline belonged to\n",
    "label = [] # the label provided by the participant\n",
    "spline_svg_string = [] # the svg spline string that earned this label\n",
    "sketch_svg_string = [] # the entire svg string correponding to this sketch\n",
    "annotation_flag = [] # this is True if all splines were labeled as the same thing\n",
    "annotation_spline_id = [] #unique identifier for specific annotation of a spline\n",
    "png=[] #png string for the annotated sketch\n",
    "stroke_id=[]\n",
    "\n",
    "## loop through all the unique assignments that have submitted things\n",
    "for this_assignment, aID in enumerate(unique_assignments):\n",
    "    if this_assignment%100==0:\n",
    "        print 'Analyzing sketches from assignment {} of {}  ...'.format(this_assignment, len(unique_assignments))\n",
    "\n",
    "    ### get all the sketch recs for this assignment\n",
    "    sketch_recs = coll.find({'$and': [{'iterationName':iterationName}, {'aID':aID}]}).sort('time')\n",
    "\n",
    "    try:\n",
    "\n",
    "        for sketch_ind,sketch in enumerate(sketch_recs):\n",
    "            ## get annotations embedded within record\n",
    "            sketch_cat = sketch['category']\n",
    "            annotations_string = sketch['annotations']\n",
    "    \n",
    "            ## convert to json dictionary\n",
    "            _annotations_dict = json.loads(annotations_string)  \n",
    "           \n",
    "            annotations_dict = _annotations_dict[0][sketch_cat]\n",
    "            png_string = _annotations_dict[0]['png']\n",
    "            num_splines = len(annotations_dict)\n",
    "            for annotation in annotations_dict:\n",
    "                assert sketch['numSplines']==num_splines                \n",
    "                ## get spline-level metadata\n",
    "            \n",
    "                workerID.append(h.encode(key,sketch['wID']))\n",
    "                label.append(annotation['label'])\n",
    "                stroke_num.append(annotation['strokeNum'])\n",
    "                spline_svg_string.append(annotation['svgString'])\n",
    "                cumulative_spline_num.append(annotation['cumulativeSplineNum'])\n",
    "                within_stroke_spline_num.append(annotation['withinStrokeSplineNum'])\n",
    "                time_clicked.append(annotation['timeClicked'])\n",
    "                time_labeled.append(annotation['timeLabeled'])\n",
    "                spline_id.append('{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],annotation['cumulativeSplineNum']))\n",
    "                stroke_id.append('{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],annotation['strokeNum']))\n",
    "                cumulative_bout_num.append(annotation['boutNum'])\n",
    "                part_bout_num.append(annotation['partBoutNum'])\n",
    "                ## get sketch-level metadata\n",
    "                orig_gameID.append(sketch['originalGameID'])   \n",
    "                outcome.append(sketch['originalOutcome'])\n",
    "                orig_trial_num.append(sketch['originalTrialNum'])\n",
    "                sketch_id.append('{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum']))\n",
    "                annotation_id.append('{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],sketch['aID']))\n",
    "                assignmentID.append(sketch['aID'])\n",
    "                category.append(sketch['category'])\n",
    "                target.append(sketch['target'])\n",
    "                png.append(png_string)\n",
    "                condition.append(sketch['condition'])\n",
    "                time_submitted.append(sketch['time'])\n",
    "                trial_num.append(sketch['trialNum'])\n",
    "                num_splines_in_sketch.append(sketch['numSplines'])\n",
    "                num_strokes_in_sketch.append(sketch['numStrokes'])\n",
    "                sketch_svg_string.append(sketch['svg'])\n",
    "                annotation_flag.append(sketch['sameAnnotflag'])\n",
    "                annotation_spline_id.append('{}_{}_{}_{}'.format(sketch['originalGameID'],sketch['originalTrialNum'],sketch['aID'],annotation['cumulativeSplineNum']))\n",
    "                \n",
    "    except AssertionError:\n",
    "        print 'There were unequal numbers for sketch[\"numSplines\"] vs. num_splines for sketch {} from {}'.\\\n",
    "                format(sketch['trialNum'], sketch['aID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make group dataframe \n",
    "D = pd.DataFrame([workerID,orig_gameID, orig_trial_num, outcome, sketch_id, category, assignmentID,  target, \\\n",
    "                  annotation_id, condition, trial_num, time_submitted,\\\n",
    "                 time_labeled, time_clicked, num_strokes_in_sketch, num_splines_in_sketch,\\\n",
    "                 stroke_num, cumulative_spline_num, within_stroke_spline_num, cumulative_bout_num,\\\n",
    "                 part_bout_num, label, spline_svg_string, sketch_svg_string, spline_id, stroke_id,\\\n",
    "                  annotation_spline_id,png])\n",
    "D = D.transpose()\n",
    "D.columns = ['workerID','orig_gameID', 'orig_trial_num','outcome', 'sketch_id', 'category', 'assignmentID', 'target',\\\n",
    "             'annotation_id', 'condition', 'trial_num', 'time_submitted',\\\n",
    "             'time_labeled', 'time_clicked', 'num_strokes_in_sketch', 'num_splines_in_sketch',\\\n",
    "             'stroke_num', 'cumulative_spline_num', 'within_stroke_spline_num', 'cumulative_bout_num', 'part_bout_num', 'label',\\\n",
    "             'spline_svg_string', 'sketch_svg_string', 'spline_id','stroke_id','annotation_spline_id','png']\n",
    "D=D[D['assignmentID']!='']\n",
    "\n",
    "\n",
    "print 'Annotations dataframe contains {} rows and {} columns.'.format(D.shape[0],D.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check to see what dataframe looks like\n",
    "D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Changing the NAs to \"None\" strings\n",
    "\n",
    "for ind, row in D.iterrows():\n",
    "    if row['label'] is None:\n",
    "        row['label'] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a count of how many unique sketches have been annotated\n",
    "\n",
    "unique_sketches = np.unique(D['sketch_id'].values)\n",
    "print 'We have {} unique sketches.'.format(len(unique_sketches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###How many unique annotations do we have in total?\n",
    "len(D['annotation_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Removing any annotations that don't have all splines annotated\n",
    "\n",
    "for this_sketch in unique_sketches:\n",
    "    DS=D[D['sketch_id']==this_sketch]\n",
    "    for this_annot in np.unique(DS['annotation_id']):\n",
    "        DSS= DS[DS['annotation_id']==this_annot]\n",
    "        if DSS[DSS['label']== 'None'].shape[0]>0:\n",
    "            D=D[D['annotation_id']!=this_annot]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##How many annotations after filtering?\n",
    "len(D['annotation_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations and desriptive statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of annotations per sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get number of times each sketch has been annotated\n",
    "num_times_annotated = []\n",
    "for this_sketch_id in unique_sketches:\n",
    "    num_times_annotated.append(D[D['sketch_id']==this_sketch_id]['assignmentID'].nunique())\n",
    "    \n",
    "## make a histogram\n",
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(6,5))\n",
    "h = plt.hist(num_times_annotated)\n",
    "plt.xticks(np.arange(0, 4, step=1))\n",
    "plt.title('Times each sketch has been annotated')\n",
    "plt.ylabel('number of sketches')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Subesttting for sketches that have been annotated 3 times\n",
    "num_annots=3\n",
    "##Why are some assignment IDs blank?\n",
    "D=D[D['assignmentID']!='']\n",
    "for this_sketch_id in unique_sketches:\n",
    "    if D[D['sketch_id']==this_sketch_id]['assignmentID'].nunique()!=num_annots:\n",
    "        D=D[D['sketch_id']!=this_sketch_id]\n",
    "unique_sketches = np.unique(D['sketch_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##How many sketches do we have with 3 annotations?\n",
    "len(np.unique(D.sketch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at time taken to annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make sure the number of splines for each sketch is consistent across annotations\n",
    "for this_sketch in unique_sketches:\n",
    "    assert len(np.unique(D[D['sketch_id']==this_sketch]['num_splines_in_sketch'].values))==1\n",
    "\n",
    "unique_annotation_trials = np.unique(D['annotation_id'].values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get annotation time for each annotation trial\n",
    "annotation_time = []\n",
    "spline_number_in_sketch = []\n",
    "\n",
    "for this_annotation_trial in unique_annotation_trials:\n",
    "    earliest_click = float(np.min(D[D['annotation_id']==this_annotation_trial]['time_clicked']))\n",
    "    ## all of the splines were submitted at the same time, so time_submitted should be identical for all splines in an annotation trial\n",
    "    assert len(np.unique(D[D['annotation_id']==this_annotation_trial]['time_submitted'].values))==1\n",
    "    final_submission = np.unique(D[D['annotation_id']==this_annotation_trial]['time_submitted'].values)[0]\n",
    "    annotation_time.append(final_submission-earliest_click)        \n",
    "    if np.isnan(final_submission) or np.isnan(earliest_click):\n",
    "        print 'One of these timestamps is a NaN. Probably means that the participant skipped this trial:'\n",
    "        print this_annotation_trial\n",
    "        print 'final_submission: {}, earliest_click: {}'.format(final_submission, earliest_click)\n",
    "    #### then we will extract how \"complex\" each sketch i\n",
    "    assert len(np.unique(D[D['annotation_id']==this_annotation_trial]['num_splines_in_sketch'].values))==1    \n",
    "    spline_number_in_sketch.append(np.unique(D[D['annotation_id']==this_annotation_trial]['num_splines_in_sketch'])[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert annotation time to seconds\n",
    "annotation_time_seconds = np.array(annotation_time)/1000\n",
    "\n",
    "## make dataframe with annotation time and spline number\n",
    "unique_annotation_trials, spline_number_in_sketch, annotation_time_seconds = map(list, [unique_annotation_trials, spline_number_in_sketch, annotation_time_seconds])\n",
    "T = pd.DataFrame([unique_annotation_trials,spline_number_in_sketch,annotation_time_seconds])\n",
    "T = T.transpose()\n",
    "T.columns = ['annotation_trial','spline_number_in_sketch','annotation_time']\n",
    "\n",
    "## some preprocessing of T\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)\n",
    "\n",
    "\n",
    "## make numeric types\n",
    "T = h.convert_numeric(T,'spline_number_in_sketch')\n",
    "T = h.convert_numeric(T,'annotation_time')\n",
    "\n",
    "## also remove the skipped trial where annotation time is a NaN\n",
    "T = T[~np.isnan(T['annotation_time'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make scatterplot of relationship between annotation time and spline number\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x='annotation_time',\n",
    "                y='spline_number_in_sketch',\n",
    "                data=T)\n",
    "plt.ylabel('number of splines in sketch')\n",
    "plt.xlabel('annotation time (s)')\n",
    "plt.title('Do more complex sketches take longer to annotate?')\n",
    "plt.xlim(0,60*5) ## 5 minute cutoff ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.spearmanr(T['annotation_time'],T['spline_number_in_sketch'])\n",
    "print 'Spearman correlation between annotation time and spline number in sketch' \n",
    "print 'r = {}, p = {}'.format(r,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at part occurrence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the list of unique labels applied to sketches\n",
    "unique_labels = np.unique(D.label.values)\n",
    "\n",
    "## Removing Nones and obviously wrong super long lables\n",
    "unique_labels = [i for i in unique_labels if i is not None]\n",
    "unique_labels = [i for i in unique_labels if len(i)<900]\n",
    "\n",
    "print 'we have {} unique labels'.format(len( unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get a list of categories\n",
    "unique_cats = np.unique(D['category'])\n",
    "\n",
    "##Create empty dictionary with categories as keys. We will use this to store part occurrence data for our categories\n",
    "label_vect_dict = {unique_cats[0]:None,unique_cats[1]:None,unique_cats[2]:None,unique_cats[3]:None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create vectors that contain the number of part instances in each sketch\n",
    "\n",
    "for category in unique_cats:\n",
    "    DS= D[D['category']==category]\n",
    "    unique_sketches_in_cat = np.unique(DS['sketch_id'])\n",
    "    unique_labels_in_cat = np.unique(DS['label'])\n",
    "    ## initialize matrix that has the correct dimensions\n",
    "    Label_Vec = np.zeros((len(unique_sketches_in_cat),len(unique_labels_in_cat)), dtype=int)\n",
    "    unique_labels_in_cat= np.array(unique_labels_in_cat)\n",
    "    for s,this_sketch in enumerate(unique_sketches_in_cat):\n",
    "        label_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        DSS = DS[DS['sketch_id']==this_sketch]\n",
    "        annotation_ids = np.unique(DSS['annotation_id'].values)    \n",
    "        for this_annotation in annotation_ids:\n",
    "            DSA = DSS[DSS['annotation_id']==this_annotation]\n",
    "            label_list = DSA.label.values\n",
    "            for this_label in label_list:\n",
    "                label_ind = unique_labels_in_cat==this_label\n",
    "                label_vec[label_ind] += 1\n",
    "            \n",
    "        Label_Vec[s,:]=label_vec/num_annots\n",
    "    label_vect_dict[category]= Label_Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[D['category']=='car'].label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maplist={}\n",
    "maplist\n",
    "{'body':['59 decal','Body and hood','Body and windshield','Gas Cap', 'Gas tank','Logo','Number','Number Decal','logo','grill',\\\n",
    "                'Grille','Grill','hubcap','seat','grille','ROOF','number','59 decal'],\n",
    " 'bumper':[],\n",
    " 'door':['DOOR HANDLE'],\n",
    " 'headlight':[],\n",
    " 'hood':[],\n",
    " 'trunk':[],\n",
    " 'unknown':['Letter R','Letter e','Letter D','Says the word Drive'],\n",
    " 'wheel':['rim','Tire',],\n",
    " 'window':[],\n",
    " 'windshield':[]\n",
    "}\n",
    "maplist[]\n",
    "\n",
    "# D[D['label'] in maplist, 'label']='body'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels_dict['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels=[]\n",
    "valid_labels_dict={}\n",
    "for category in unique_cats:\n",
    "    vect = label_vect_dict[category]\n",
    "    thresh = 50\n",
    "    #print 'These are the labels that appear at least {} times:'.format(thresh)\n",
    "    #print unique_labels[np.sum(Label_Vec,0)>thresh]\n",
    "    unique_labels_in_cat = np.unique(D[D['category']==category]['label'])\n",
    "    plot_labels= unique_labels_in_cat[np.sum(vect,0)>thresh]\n",
    "    valid_labels_dict[category]=plot_labels\n",
    "    valid_labels.append(plot_labels)\n",
    "\n",
    "\n",
    "    prop_labels=[]\n",
    "    for part in plot_labels:\n",
    "        DS=D[D['category']==category]\n",
    "        prop_labels.append(DS[DS['label']==part]['annotation_id'].nunique()/DS['annotation_id'].nunique())\n",
    "    \n",
    "    \n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.ylim(0,1)\n",
    "    h = plt.bar(plot_labels,prop_labels)\n",
    "    plt.title('Proportion of {} annotations with labels'.format(category))\n",
    "    plt.ylabel('proportion of annotations')\n",
    "    plt.xlabel('Part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##flattening valid labels\n",
    "valid_labels = [item for sublist in valid_labels for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a stroke-level dataframe that takes the mode value of annotation for its children splines to set as its\n",
    "##label value\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "stroke_svgs=OrderedDict()\n",
    "for category in unique_cats:\n",
    "    DS=D[D['category']==category]\n",
    "    for sketch in np.unique(DS['sketch_id']):\n",
    "        DSS=DS[DS['sketch_id']==sketch]\n",
    "        for stroke in np.unique(DSS['stroke_num']):\n",
    "            DSA=DSS[DSS['stroke_num']==stroke]\n",
    "            DSA=DSA.reset_index()\n",
    "            stroke_svgs[DSA['stroke_id'][0]] = DSA['sketch_svg_string'][0][stroke]\n",
    "\n",
    "            \n",
    "            \n",
    "stroke_svg_df= pd.DataFrame.from_dict(stroke_svgs, orient='index')    \n",
    "stroke_group_data= D.groupby('stroke_id').agg(lambda x: Counter(x).most_common(1)[0][0])\n",
    "labels= pd.DataFrame(stroke_group_data[['sketch_id','label','stroke_num','condition','target','category','outcome']])\n",
    "stroke_df=pd.merge(stroke_svg_df,labels,left_index=True, right_index =True)\n",
    "stroke_df.reset_index(level=0, inplace=True)\n",
    "stroke_df=stroke_df.rename(index=str, columns={\"index\": \"stroke_id\", 0: \"svg\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding total arclength information to stroke dataframe\n",
    "\n",
    "from svgpathtools import parse_path\n",
    "import svgpathtools\n",
    "\n",
    "stroke_df['arc_length'] = \"\"\n",
    "for s,stroke in stroke_df.iterrows():\n",
    "    try:\n",
    "        stroke_df['arc_length'][s] = parse_path(stroke['svg']).length()\n",
    "    except ZeroDivisionError:\n",
    "        print 'zero div error'\n",
    "        stroke_df['arc_length'][s] = 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving out the PNG for the sketches\n",
    "run=False\n",
    "if run==True:\n",
    "    from matplotlib.pyplot import imshow\n",
    "    import base64\n",
    "\n",
    "\n",
    "    #num_diff_annots = []\n",
    "    for this_sketch_id in unique_sketches:\n",
    "        DS=D[D['sketch_id']==this_sketch_id]\n",
    "        unique_splines = np.unique(DS['cumulative_spline_num'])\n",
    "        for i,this_spline in enumerate(unique_splines):\n",
    "            DSS =DS[DS['cumulative_spline_num']==this_spline]\n",
    "            num_diff_annots= len(np.unique(DSS['label']))\n",
    "        if num_diff_annots>0:  ##Will update this conditional once we have more annots\n",
    "            for instance in np.unique(DS['annotation_id']):\n",
    "                    imgdata = base64.b64decode(DS[DS['annotation_id']==instance].iloc[0]['png'])\n",
    "                    filename = '{}_{}'.format(instance, DS[DS['annotation_id']==instance].iloc[0]['target'])  # I assume you have a way of picking unique filenames\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        f.write(imgdata)\n",
    "                    im = Image.open(filename)\n",
    "                    plt.figure()\n",
    "                    imshow(im)\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                    #plt.savefig(xx)\n",
    "run=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making part-transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Setting up for building transition matrices for each different category\n",
    "from itertools import product as p\n",
    "run=False\n",
    "if run==True:\n",
    "   \n",
    "    tm_dict={}\n",
    "    for category in unique_cats:\n",
    "        stroke_df_s = stroke_df[stroke_df['category']==category]  \n",
    "        num_uniq_labs = len(np.unique(stroke_df_s['label']))\n",
    "        temp_array = np.zeros([num_uniq_labs*num_uniq_labs,2],dtype='|S50')\n",
    "        ind=0\n",
    "        for roll in p(stroke_df_s['label'].unique().tolist(), repeat = 2):\n",
    "            temp_array[ind,]= roll\n",
    "            ind+=1\n",
    "        for sketch in stroke_df_s.sketch_id.unique():\n",
    "            sketch_df= stroke_df_s[stroke_df_s.sketch_id==sketch]\n",
    "            sketch_df['incr_stroke_num'] = sketch_df['stroke_num']+1\n",
    "            tm_df=sketch_df.merge(sketch_df, right_on='stroke_num', left_on='incr_stroke_num', how='inner' )\n",
    "            plot_matrix_x= tm_df.label_x.append(pd.Series(temp_array[:,0]))\n",
    "            plot_matrix_y=tm_df.label_y.append(pd.Series(temp_array[:,1]))\n",
    "            ct_df= pd.crosstab(plot_matrix_x, plot_matrix_y)-1\n",
    "            #ct_df= pd.crosstab(tm_df.label_x, tm_df.label_y)\n",
    "            mat= np.matrix(ct_df).sum()\n",
    "            plot_df = ct_df.div(mat, axis=0).round(2)\n",
    "            plot_df=plot_df.fillna(0)\n",
    "            tm_dict[sketch]= plot_df\n",
    "\n",
    "    for category in unique_cats:\n",
    "        cat_matrices=[]\n",
    "        DS=D[D['category']==category]\n",
    "        for sketch in DS['sketch_id'].unique():\n",
    "            cat_matrices.append(tm_dict[sketch])\n",
    "        fig,ax=plt.subplots(1, 1, figsize = (10, 8), dpi=150)\n",
    "        agg_matrix= sum(cat_matrices)\n",
    "        divider=np.matrix(agg_matrix).sum()\n",
    "        agg_matrix = agg_matrix.div(divider, axis=0).round(2)\n",
    "        sns.heatmap(agg_matrix,cmap=\"YlGnBu\", annot=True)\n",
    "        plt.title(\"Part transition matrix for {}\".format(category))\n",
    "        ax.set_ylabel('')    \n",
    "        ax.set_xlabel('')\n",
    "\n",
    "run=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the number of unique labels assigned to a given spline across annotations\n",
    "num_diff_annots = []\n",
    "for this_cat in unique_cats:\n",
    "    DS=D[D['category']==this_cat]\n",
    "    labels = valid_labels_dict[this_cat]\n",
    "    unique_sketches_in_cat=np.unique(DS['sketch_id'])\n",
    "    \n",
    "\n",
    "   \n",
    "    for this_sketch_id in unique_sketches_in_cat:\n",
    "        DSA=DS[DS['sketch_id']==this_sketch_id]\n",
    "        unique_splines = np.unique(DSA['cumulative_spline_num'])\n",
    "        for i,this_spline in enumerate(unique_splines):\n",
    "            DSB =DSA[DSA['cumulative_spline_num']==this_spline]\n",
    "            numannots= 4-len(np.unique(DSB['label']))\n",
    "            if numannots==0:\n",
    "                numannots=1\n",
    "            num_diff_annots.append(numannots)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting variability in spline annots\n",
    "h= plt.hist(num_diff_annots, bins= range(1,5), align='left', density='True')\n",
    "plt.title('Inter-annotator reliability')\n",
    "plt.ylabel('proportion of splines')\n",
    "plt.xlabel('Annotator agreement on label')\n",
    "plt.xticks([1,2,3],['0/3','2/3','3/3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_df= D.groupby('spline_id').agg(lambda x: Counter(x).most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_cat in unique_cats:\n",
    "    labels = valid_labels_dict[this_cat]\n",
    "    DS=spline_df[spline_df['category']==this_cat]\n",
    "    spline_annots_per_stroke = []\n",
    "    unique_sketches_in_cat= np.unique(DS['sketch_id'])\n",
    "    for this_sketch_id in unique_sketches_in_cat:\n",
    "        DSA=DS[DS['sketch_id']==this_sketch_id]\n",
    "        unique_strokes = np.unique(DSA['stroke_num'])\n",
    "        for i,this_stroke in enumerate(unique_strokes):\n",
    "            DSB =DSA[DSA['stroke_num']==this_stroke]\n",
    "            numlabels= DSB['label'].nunique()\n",
    "            spline_annots_per_stroke.append(numlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h= plt.hist(spline_annots_per_stroke, bins =range(1,8), align='left', density=\"True\")\n",
    "plt.title('Within-stroke label agreement')\n",
    "plt.ylabel('proportion of strokes')\n",
    "plt.xlabel('number of different labels within stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_cat in unique_cats:\n",
    "    DS=stroke_df[stroke_df['category']==this_cat]\n",
    "    labels= valid_labels_dict[this_cat]\n",
    "    strokes_in_part_vect = np.zeros((len(np.unique(DS['sketch_id']))*len(labels),3), dtype='|a1000')\n",
    "    ind=0\n",
    "    for this_sketch in np.unique(DS['sketch_id']):    \n",
    "        DSA= DS[DS['sketch_id']==this_sketch]\n",
    "        for this_label in labels:\n",
    "            DSB=DSA[DSA['label']==this_label]\n",
    "            strokes_in_part_vect[ind,]=[this_sketch, this_label,len(np.unique(DSB['stroke_num']))]\n",
    "            ind+=1\n",
    "    strokes_in_part_vect=strokes_in_part_vect[~np.all(strokes_in_part_vect == '', axis=1)]\n",
    "    strokes_in_part_df= pd.DataFrame(strokes_in_part_vect, columns=['sketch_id','part','num_strokes'])\n",
    "    strokes_in_part_df['num_strokes']=pd.to_numeric(strokes_in_part_df['num_strokes'])\n",
    "    plt.figure()\n",
    "    b=sns.barplot(x='part',y='num_strokes',data=strokes_in_part_df,ci=95,capsize=0.3, errwidth= 3)\n",
    "    for item in b.get_xticklabels():\n",
    "        item.set_rotation(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a dictionary of sketch_id with associated part sequences\n",
    "seq_dict={}\n",
    "for this_sketch in np.unique(stroke_df['sketch_id']):\n",
    "    parts_list=[]\n",
    "    DS=stroke_df[stroke_df['sketch_id']==this_sketch]\n",
    "    for i, row in DS.iterrows():\n",
    "        parts_list.append(stroke_df['label'][i])\n",
    "    seq_dict[this_sketch]=parts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions for getting 'mean streak_length' from a particular sketch for ground truth and scrambled part orders\n",
    "\n",
    "import random\n",
    "\n",
    "def get_mean_streak(sketch_id):\n",
    "    parts = seq_dict[sketch_id]\n",
    "    streak_counter=1\n",
    "    list_of_streaks=[]\n",
    "    for obj in range(len(parts)-1):\n",
    "        if parts[obj]==parts[obj+1]:\n",
    "            streak_counter+=1\n",
    "        else:\n",
    "            list_of_streaks.append(streak_counter)\n",
    "            streak_counter=1 \n",
    "    list_of_streaks.append(streak_counter)\n",
    "    return np.mean(list_of_streaks)\n",
    "\n",
    "def get_scramble_mean_streak(sketch_id):\n",
    "    parts = seq_dict[sketch_id]\n",
    "    scram_parts=random.sample(parts,len(parts))\n",
    "    streak_counter=1\n",
    "    list_of_streaks=[]\n",
    "    for obj in range(len(scram_parts)-1):\n",
    "        if scram_parts[obj]==scram_parts[obj+1]:\n",
    "            streak_counter+=1\n",
    "        else:\n",
    "            list_of_streaks.append(streak_counter)\n",
    "            streak_counter=1 \n",
    "    list_of_streaks.append(streak_counter)\n",
    "    return np.mean(list_of_streaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating over all sketches to get mean streakiness for each sketch_id\n",
    "\n",
    "gt_streak_mean={}\n",
    "for this_cat in unique_cats:\n",
    "    DS= stroke_df[stroke_df['category']==this_cat]\n",
    "    streak_mean_list=[]\n",
    "    for this_sketch in np.unique(DS['sketch_id']):\n",
    "        streak_mean_list.append(get_mean_streak(this_sketch))\n",
    "    gt_streak_mean[this_cat]=np.mean(streak_mean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_streak_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streak_diff_dict={}\n",
    "for this_cat in unique_cats:\n",
    "    mean_streak_diff_list=[]\n",
    "    DS=stroke_df[stroke_df['category']==this_cat]\n",
    "    for i in range(1000):\n",
    "        scrambled_streaks=[] \n",
    "        real_streaks=[]\n",
    "        for sketch in np.unique(DS['sketch_id']):\n",
    "            scrambled_streaks.append(get_scramble_mean_streak(sketch))\n",
    "            real_streaks.append(get_mean_streak(sketch))\n",
    "        mean_streak_diff_list.append(np.mean(real_streaks)-np.mean(scrambled_streaks))\n",
    "    streak_diff_dict[this_cat]=mean_streak_diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(streak_diff_dict['bird'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIPlot(category): \n",
    "    stroke_df_lite_ss=stroke_df[stroke_df['category']==category]\n",
    "    mean_streak_diff_list=[]\n",
    "    for i in range(1000):\n",
    "        this_round_scrambled_streak=[] \n",
    "        this_round_real_streak=[]\n",
    "        for sketch in np.unique(stroke_df_lite_ss['sketch_id']):\n",
    "            this_round_real_streak.append(get_mean_streak(sketch))\n",
    "            this_round_scrambled_streak.append(get_scramble_mean_streak(sketch))\n",
    "        mean_streak_diff_list.append(np.mean(this_round_real_streak)-np.mean(this_round_scrambled_streak))\n",
    "    perm_observed_mean_streak_diff = np.mean(mean_streak_diff_list)    \n",
    "    lb=np.percentile(mean_streak_diff_list,2.5)\n",
    "    ub=np.percentile(mean_streak_diff_list,97.5)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    h=sns.distplot(mean_streak_diff_list,kde=False,hist=True,norm_hist=False)\n",
    "    plt.axvline(perm_observed_mean_streak_diff, color='yellow', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(lb, color='orange', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(ub, color='orange', linestyle='solid', linewidth=2)\n",
    "    plt.title(category)\n",
    "    plt.ylabel('count')\n",
    "    plt.xlabel('streak length difference')\n",
    "    plt.legend(['mean','95% CI'], ncol=2, bbox_to_anchor=(1, 1.05))\n",
    "    \n",
    "    plt.savefig(os.path.join(plot_dir,'Streakiness Diff'),edgecolor='w',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return np.mean(mean_streak_diff_list), np.std(mean_streak_diff_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def CIPlotCatCond(category,condition): \n",
    "    stroke_df_lite_ss=stroke_df[(stroke_df['category']==category)&(stroke_df['condition']==condition)]\n",
    "    mean_streak_diff_list=[]\n",
    "    for i in range(1000):\n",
    "        this_round_scrambled_streak=[] \n",
    "        this_round_real_streak=[]\n",
    "        for sketch in np.unique(stroke_df_lite_ss['sketch_id']):\n",
    "            this_round_real_streak.append(get_mean_streak(sketch))\n",
    "            this_round_scrambled_streak.append(get_scramble_mean_streak(sketch))\n",
    "        mean_streak_diff_list.append(np.mean(this_round_real_streak)-np.mean(this_round_scrambled_streak))\n",
    "    perm_observed_mean_streak_diff = np.mean(mean_streak_diff_list)    \n",
    "    lb=np.percentile(mean_streak_diff_list,2.5)\n",
    "    ub=np.percentile(mean_streak_diff_list,97.5)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    h=sns.distplot(mean_streak_diff_list,kde=False,hist=True,norm_hist=False)\n",
    "    plt.axvline(perm_observed_mean_streak_diff, color='yellow', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(lb, color='orange', linestyle='solid', linewidth=2)\n",
    "    plt.axvline(ub, color='orange', linestyle='solid', linewidth=2)\n",
    "    plt.title('{}_{}'.format(category,condition))\n",
    "    plt.ylabel('count')\n",
    "    plt.xlabel('streak length difference')\n",
    "    plt.legend(['mean','95% CI'], ncol=2, bbox_to_anchor=(1, 1.05))\n",
    "    \n",
    "    plt.savefig(os.path.join(plot_dir,'mean_streak_difference_{}_{}'.format(category, condition)),edgecolor='w',bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return perm_observed_mean_streak_diff, lb, ub\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_cat in unique_cats:\n",
    "    CIPlot(this_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_condition in np.unique(stroke_df['condition']):\n",
    "    for this_category in np.unique(stroke_df['category']):\n",
    "        CIPlotCatCond(this_category, this_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_C= D[D['category']=='dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_C.groupby('label').mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at stroke  variation between parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Investigating how stroke length varies between parts given a category of objects \n",
    "\n",
    "for category in unique_cats:\n",
    "    DS= D[D['category']==category]\n",
    "    num_unique_labs = len(DS['label'].unique())\n",
    "    strokes_in_part_vect = np.zeros((len(np.unique(DS['annotation_id']))*num_unique_labs,3), dtype='|a1000')\n",
    "    ind=0\n",
    "    for this_annotation in np.unique(DS['annotation_id']):    \n",
    "        DSA= DS[DS['annotation_id']==this_annotation]\n",
    "        for this_label in np.unique(DS['label']):\n",
    "            DSB=DSA[DSA['label']==this_label]\n",
    "            strokes_in_part_vect[ind,]=[this_annotation, this_label,len(np.unique(DSB['stroke_num']))]\n",
    "            ind+=1\n",
    "    strokes_in_part_vect=strokes_in_part_vect[~np.all(strokes_in_part_vect == '', axis=1)]\n",
    "    strokes_in_part_df= pd.DataFrame(strokes_in_part_vect, columns=['annotation_id','part','num_strokes'])\n",
    "    strokes_in_part_df['num_strokes']=pd.to_numeric(strokes_in_part_df['num_strokes'])\n",
    "    fig,ax=plt.subplots(1, 1, figsize = (10, 8), dpi=150)\n",
    "    sns.barplot(x='part',y='num_strokes',data=strokes_in_part_df,ci=95,capsize=0.3, errwidth= 3)\n",
    "    plt.title('Average number of strokes for {} parts'.format(category))\n",
    "    plt.ylabel('Number of strokes')\n",
    "    plt.xlabel('Part')\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Investigating how arc length varies between parts\n",
    "\n",
    "for category in unique_cats:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='label', y='arc_length', data=stroke_df[stroke_df['category']=='dog'], ci=68,capsize=0.3, errwidth= 3)\n",
    "    plt.title('Average stroke lengths for {} parts'.format(category))\n",
    "    plt.ylabel('arc length')\n",
    "    plt.xlabel('part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Investigating how arc length varies between parts x conditions\n",
    "\n",
    "for category in unique_cats:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='label',y='arc_length',hue='condition', data=stroke_df[stroke_df['category']==category],ci=68,capsize=0.3, errwidth= 3)\n",
    "    plt.title('Average stroke lengths for {} parts'.format(category))\n",
    "    plt.ylabel('Arc length')\n",
    "    plt.xlabel('Part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###Might Delete this - calculating average arc length per part manually####\n",
    "# part_lengths={}\n",
    "# for category in unique_cats:\n",
    "#     stroke_df_lite= stroke_df[stroke_df['category']==category]\n",
    "#     arc_length_dict = OrderedDict()\n",
    "#     for label in np.unique(stroke_df_lite['label']):\n",
    "#         stroke_df_lite0= stroke_df_lite[stroke_df_lite['label']==label]\n",
    "#         path_length=0\n",
    "#         for stroke in np.unique(stroke_df_lite0['stroke_id']):\n",
    "#             path = parse_path(stroke_df_lite0[stroke_df_lite['stroke_id']==stroke]['svg'].iloc[0])\n",
    "#             path_length= path_length+path.length()\n",
    "#         arc_length_dict[label]= path_length/len(stroke_df_lite0)\n",
    "#     part_lengths[category]=arc_length_dict\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at annotation bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Investigating the number of parts for each part within a category. Does this number correspond to number \n",
    "###of strokes with that part label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['part_bout_num'] = pd.to_numeric(D['part_bout_num'])\n",
    "\n",
    "for category in unique_cats:\n",
    "    DS=D[D['category']==category]\n",
    "    unique_labels_in_cat= DS['label'].unique()\n",
    "    plot_vect = np.zeros([1,2], dtype='|a20')\n",
    "    for label in unique_labels_in_cat:\n",
    "        DSA=DS[DS['label']==label]\n",
    "        total_bouts=0\n",
    "        for sketch in DSA['sketch_id'].unique():\n",
    "            DSB= DSA[DSA['sketch_id']==sketch]\n",
    "            num_bouts = len(DSB['part_bout_num'].unique())\n",
    "            temp= np.array([label, num_bouts], dtype= '|a20')\n",
    "            plot_vect=np.vstack((plot_vect, temp))\n",
    "    plot_vect=np.delete(plot_vect, (0), axis=0)  \n",
    "    plot_df= pd.DataFrame(plot_vect, columns=['label','num_bouts'])\n",
    "    plot_df['num_bouts']=pd.to_numeric(plot_df['num_bouts'])\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='label',y='num_bouts',data= plot_df,capsize=0.3)\n",
    "    plt.title('Average bout numbers for {} parts'.format(category))\n",
    "    plt.ylabel('Average Number of Bouts')\n",
    "    plt.xlabel('Part')\n",
    "\n",
    "        #label_group_data=DS.groupby('label').agg({'part_bout_num':\"mean\"})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sketch vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Creating different vectors for each category, might look at this later\n",
    "\n",
    "label_vect_dict={}\n",
    "for cat in unique_cats:\n",
    "    DS= stroke_df[stroke_df['category']==cat]\n",
    "    unique_labels_in_cat=valid_labels_dict[cat]\n",
    "    unique_sketches_in_cat=DS['sketch_id'].unique()\n",
    "    Label_Vec = np.zeros((len(unique_sketches_in_cat),len(unique_labels_in_cat)*2), dtype=int)\n",
    "    arc_length_vec = np.zeros((len(unique_sketches_in_cat),len(valid_labels_dict[cat])), dtype=int)\n",
    "    for s,sketch in enumerate(unique_sketches_in_cat):\n",
    "        label_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        arc_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        DSA=DS[DS['sketch_id']==sketch]\n",
    "        label_list = DSA.label.values        \n",
    "        for label in label_list:\n",
    "            if label in unique_labels_in_cat:\n",
    "                label_ind = unique_labels_in_cat==label\n",
    "                label_vec[label_ind] += 1\n",
    "        for label in unique_labels_in_cat:\n",
    "            DSB=DSA[DSA['label']==label]\n",
    "            label_ind = unique_labels_in_cat==label\n",
    "            arc_vec[label_ind] = DSB['arc_length'].sum()\n",
    "            \n",
    "        \n",
    "        Label_Vec[s,0:len(unique_labels_in_cat)]=label_vec\n",
    "        Label_Vec[s,len(unique_labels_in_cat):len(unique_labels_in_cat)*2]=arc_vec\n",
    "    label_vect_dict[cat]= Label_Vec\n",
    "    \n",
    "\n",
    "##z scoring\n",
    "\n",
    "for cat in unique_cats:\n",
    "    label_vect_dict[cat] = stats.zscore(label_vect_dict[cat], axis=1, ddof=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This is where we make a num unique labels * 2 X number of sketches vector \n",
    "\n",
    "feature_vec = np.zeros((len(stroke_df.sketch_id.unique()),len(valid_labels)*2), dtype=int)\n",
    "ind=0\n",
    "start_pos=0\n",
    "end_pos=0\n",
    "meta_list=[]\n",
    "cols = ['sketch_id','target','condition','category','outcome']\n",
    "\n",
    "for cat in unique_cats:\n",
    "  \n",
    "    DS= stroke_df[stroke_df['category']==cat]\n",
    "    unique_labels_in_cat=valid_labels_dict[cat]\n",
    "    unique_sketches_in_cat=DS['sketch_id'].unique()\n",
    "    start_pos = end_pos\n",
    "    end_pos+= len(unique_labels_in_cat)\n",
    "    print start_pos, end_pos\n",
    "    Label_Vec = np.zeros((len(unique_sketches_in_cat),len(unique_labels_in_cat)*2), dtype=int)\n",
    "    arc_length_vec = np.zeros((len(unique_sketches_in_cat),len(valid_labels_dict[cat])), dtype=int)\n",
    "    for s,sketch in enumerate(unique_sketches_in_cat):\n",
    "        \n",
    "        label_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        arc_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        DSA=DS[DS['sketch_id']==sketch]\n",
    "      \n",
    "        meta_list.append(pd.Series([DSA['sketch_id'],DSA['target'].unique(),DSA['condition'].unique(),DSA['category'].unique(),DSA['outcome'].unique()], index=cols))\n",
    "        label_list = DSA.label.values        \n",
    "        for label in label_list:\n",
    "            if label in unique_labels_in_cat:\n",
    "                label_ind = unique_labels_in_cat==label\n",
    "                label_vec[label_ind] += 1\n",
    "        for label in unique_labels_in_cat:\n",
    "            DSB=DSA[DSA['label']==label]\n",
    "            label_ind = unique_labels_in_cat==label\n",
    "            arc_vec[label_ind] = DSB['arc_length'].sum()\n",
    "            \n",
    "        \n",
    "        feature_vec[ind,start_pos:end_pos]=label_vec\n",
    "        feature_vec[ind,start_pos+len(valid_labels):end_pos+len(valid_labels)]=arc_vec\n",
    "        ind+=1\n",
    "feature_vec_meta = pd.DataFrame(meta_list, columns=cols)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Changing column values from np arrays to strings/boolean\n",
    "\n",
    "def arr_to_str(arr):\n",
    "    return (arr[0])\n",
    "feature_vec_meta['target']=feature_vec_meta['target'].apply(arr_to_str)\n",
    "feature_vec_meta['condition']=feature_vec_meta['condition'].apply(arr_to_str)\n",
    "feature_vec_meta['category']=feature_vec_meta['category'].apply(arr_to_str)\n",
    "feature_vec_meta['outcome']=feature_vec_meta['outcome'].apply(arr_to_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df= pd.DataFrame(feature_vec, columns=[s + '_numstrokes' for s in valid_labels]+[s + '_total_arclength' for s in valid_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating a compressed version of the feature df with no duplicates for parts\n",
    "\n",
    "labs_numstrokes=[]\n",
    "labs_total_arclength=[]\n",
    "for lab in np.unique(valid_labels):\n",
    "    labs_numstrokes.append(lab +'_numstrokes')\n",
    "    labs_total_arclength.append(lab+'_total_arclength')\n",
    "feature_df_labs=labs_numstrokes+labs_total_arclength   \n",
    "feature_df_final= pd.DataFrame(columns=feature_df_labs)\n",
    "\n",
    "\n",
    "for this_lab in feature_df_labs:\n",
    "    duplicates=[col for col in feature_df if col.startswith(this_lab)]\n",
    "    feature_df_final[this_lab]= feature_df[duplicates].sum(axis=1)\n",
    "feature_df = feature_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check to make sure the df looks okay\n",
    "assert len(feature_df.columns)==len(np.unique(feature_df.columns))\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing within row within measure (numstrokes/arclength) \n",
    "\n",
    "feature_df.iloc[:,0:int(len(feature_df.columns)/2)]=feature_df.iloc[:,0:int(len(feature_df.columns)/2)].div(feature_df.iloc[:,0:int(len(feature_df.columns)/2)].sum(axis=1),axis=0)\n",
    "\n",
    "feature_df.iloc[:,int(len(feature_df.columns)/2):int(len(feature_df.columns))]=feature_df.iloc[:,int(len(feature_df.columns)/2):int(len(feature_df.columns))].div(feature_df.iloc[:,int(len(feature_df.columns)/2):int(len(feature_df.columns))].sum(axis=1),axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Execute this if we want to save a non-zscore matrix\n",
    "run=False\n",
    "if run==True:\n",
    "    feature_df.to_csv(os.path.join(features_dir,'semantic_parts_sketch_features_compressed_non-whitened.csv'))\n",
    "run=False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-scoring within columns\n",
    "\n",
    "cols=list(feature_df.columns)\n",
    "for this_col in cols:\n",
    "    feature_df[this_col]=(feature_df[this_col] - feature_df[this_col].mean())/feature_df[this_col].std(ddof=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Saving out matrices to csv/npy as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv(os.path.join(features_dir,'semantic_parts_sketch_features_compressed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(features_dir, 'semantic_parts_sketch_features'),feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec_meta.to_csv(os.path.join(csv_dir,'semantic_parts_sketch_features_meta.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature_df = pd.concat((feature_vec_meta,feature_df),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more vector visualization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading files we need\n",
    "feature_vec = np.load(os.path.join(features_dir,'semantic_parts_sketch_features.npy'))\n",
    "feature_df = pd.DataFrame.from_csv(os.path.join(features_dir,'semantic_parts_sketch_features_compressed.csv'))\n",
    "meta_df= pd.DataFrame.from_csv(os.path.join(features_dir,'semantic_parts_sketch_meta.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for this_part in np.unique(valid_labels):\n",
    "    feature_df.rename(columns={this_part:'{}_numstrokes'.format(this_part)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(feature_df.values)\n",
    "meta_df['pc_1'] = pca_result[:,0]\n",
    "meta_df['pc_2'] = pca_result[:,1] \n",
    "meta_df['pca_3'] = pca_result[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This chunk may not run because of ggplot being outdate. Will write up vis in matplotlib if necessary\n",
    "\n",
    "from ggplot import *\n",
    "\n",
    "\n",
    "cat_plot = ggplot( meta_df, aes(x='pc_1', y='pc_2', color='category') ) \\\n",
    "        + geom_point(size=75,alpha=0.8) \\\n",
    "        + ggtitle(\"First and Second Principal Components colored by category\")\n",
    "cat_plot\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_plot = ggplot( meta_df, aes(x='pc_1', y='pc_2', color='condition') ) \\\n",
    "        + geom_point(size=75,alpha=0.8) \\\n",
    "        + ggtitle(\"First and Second Principal Components colored by category\")\n",
    "cond_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_plot = ggplot( meta_df, aes(x='pc_1', y='pc_2', color='target') ) \\\n",
    "        + geom_point(size=75,alpha=0.8) \\\n",
    "        + ggtitle(\"First and Second Principal Components colored by category\")\n",
    "tar_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(feature_df.values)\n",
    "meta_df['tsne_dim_1']=tsne_results[:,0]\n",
    "meta_df['tsne_dim_2']=tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Visualizing using ggplot. Not as flexible as expected\n",
    "\n",
    "# plt.figure()\n",
    "# tsneplot = ggplot( meta_df, aes(x='tsne_dim_1', y='tsne_dim_2', color='category') ) \\\n",
    "#         + geom_point(size=70,alpha=0.1) \\\n",
    "#         + ggtitle(\"tSNE dimensions colored by category\")\n",
    "# tsneplot\n",
    "# tsneplot.save(filename = os.path.join(plot_dir,'tSNE dimensions colored by category'))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# tsneplot = ggplot( meta_df, aes(x='tsne_dim_1', y='tsne_dim_2', color='condition') ) \\\n",
    "#         + geom_point(size=70,alpha=0.1) \\\n",
    "#         + ggtitle(\"tSNE dimensions colored by condition\")\n",
    "# tsneplot\n",
    "# tsneplot.save(filename = os.path.join(plot_dir,'tSNE dimensions colored by condition'))\n",
    "\n",
    "\n",
    "# tsneplot = ggplot( meta_df, aes(x='tsne_dim_1', y='tsne_dim_2', color='target') ) \\\n",
    "#         + geom_point(size=70,alpha=0.1) \\\n",
    "#         + ggtitle(\"tSNE dimensions colored by target\")\\\n",
    "#         + x_label(\"die\")\n",
    "# tsneplot\n",
    "# tsneplot.save(filename = os.path.join(plot_dir,'tSNE dimensions colored by target'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualizing t-SNE results\n",
    "\n",
    "cat_labels = meta_df['category'].unique()\n",
    "rgb_values = sns.color_palette(\"Set2\", meta_df['category'].nunique())\n",
    "color_map_cat = dict(zip(cat_labels, rgb_values))\n",
    "\n",
    "cond_labels = meta_df['condition'].unique()\n",
    "rgb_values = sns.color_palette(\"Set2\", meta_df['condition'].nunique())\n",
    "color_map_cond = dict(zip(cond_labels, rgb_values))\n",
    "\n",
    "target_labels= meta_df['target'].unique()\n",
    "rgb_values = sns.color_palette(\"Set2\", meta_df['target'].nunique())\n",
    "color_map_target = dict(zip(target_labels, rgb_values))\n",
    "\n",
    "f=plt.figure(figsize(10,10))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "p= plt.scatter(meta_df['tsne_dim_1'],meta_df['tsne_dim_2'],c=meta_df['category'].map(color_map_cat))\n",
    "plt.ylabel('TSNE Dim 1')\n",
    "plt.xlabel('TSNE Dim 2')\n",
    "plt.tick_params(labelbottom=False, labelleft= False) \n",
    "plt.title('TSNE dimensions colored by categories')\n",
    "\n",
    "txts = []\n",
    "for cat in enumerate(cat_labels):\n",
    "        cat=cat[1]\n",
    "        txt = ax.text(xtext, ytext, str(cat), fontsize=24)\n",
    "        xtext = np.median(meta_df[meta_df['category'] == cat]['tsne_dim_1'] )      \n",
    "        ytext = np.median(meta_df[meta_df['category'] == cat]['tsne_dim_2'] )\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])  \n",
    "        \n",
    "        txts.append(txt)\n",
    "\n",
    "f.show\n",
    "plt.savefig(os.path.join(plot_dir,'TSNE dimensions colored by categories'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f=plt.figure(figsize(10,10))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "plt.scatter(meta_df['tsne_dim_1'],meta_df['tsne_dim_2'],c=meta_df['condition'].map(color_map_cond))\n",
    "plt.ylabel('TSNE Dim 1')\n",
    "plt.xlabel('TSNE Dim 2')\n",
    "plt.tick_params(labelbottom=False, labelleft= False)   \n",
    "plt.title('TSNE dimensions colored by condition')\n",
    "f.show\n",
    "plt.savefig(os.path.join(plot_dir,'TSNE dimensions colored by condition'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f=plt.figure(figsize(10,10))\n",
    "plt.scatter(meta_df['tsne_dim_1'],meta_df['tsne_dim_2'],c=meta_df['target'].map(color_map_target))\n",
    "plt.ylabel('TSNE Dim 1')\n",
    "plt.xlabel('TSNE Dim 2')\n",
    "plt.tick_params(labelbottom=False, labelleft= False) \n",
    "plt.title('TSNE dimensions colored by target')\n",
    "\n",
    "f.show\n",
    "plt.savefig(os.path.join(plot_dir,'TSNE dimensions colored by target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
